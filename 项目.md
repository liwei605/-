# 自我介绍

面试官老师您好，我叫李为，今年25岁，本硕均在重庆大学，专业是计算机科学与技术，中共党员，目前研究生在读。接下来我将介绍相关项目经验。

研究生期间，我以一作发表一篇CCF-A类的国际顶级会议DAC 一篇和以一作者CCF-A类期刊SCIS在投一篇。在论文中，我提出了资源受限移动端的智能数据去重算法FinerDedup。FinerDedup重构Linux内核I/O路径并使用指纹重复性预测算法，解决了传统移动系统中的数据去重方案指纹内存开销过高（无效指纹占用高达的70%）的问题。在此基础上我又提出RefineDedup方法，结合每个移动应用独特的访存行为，指定个性化去重方案，使得去重开销进一步降低。此外，我完成了跨平台全文检索系统FileWhole的设计与开发工作，采用Sqlite FTS5技术实现10万文件检索秒级响应，支持图片，代码，音频等主流文件的内容检索。

在本科期间在导师的指导下我实现了一种多设备协同数据去重系统并部署在OpenHarmony平台，其中我担任系统核心模块设计与开发负责人，主导分布式去重与远程访问机制开发，解决传统去重方案无法跨设备协同、存储资源浪费的问题。

实习，阿里巴巴。

在专业技能方面，我能够熟练掌握c/c++，python等语言，熟悉常见数据结构和算法。在linux开发方面，我熟悉常见的命令工具，熟悉内核基本结构和功能，具有相关内核开发经验。

英文自我介绍

Hello, I'm Li Wei from Chongqing University, majoring in computer science with a focus on storage systems. During my postgraduate studies, I published two high-quality papers and participated in numerous industry projects, which enhanced both my research skills and interpersonal abilities. I believe I am well-suited for this position. Thank you.

优缺点：
Strength: I’m confident, outgoing and express ideas clearly.

Weakness: Aircraft systems are new to me; I’ll invest focused time to master them fast.

你遇到过什么困难如何克服？

Early on, my storage-tracing tool crashed on a 1 TB dataset. I broke the pipeline into micro-modules, logged every step and wrote a delta-checker that replayed chunks until it uncovered a 4-byte alignment bug; after the fix the trace ran cleanly and supplied solid data for both papers.

## RH面试自我介绍

面试官您好，我叫李为，今年25岁，本硕均是重庆大学，专业是计算机科学与技术，目前是研究生在读。研究生期间我主要从事的方向是嵌入式，数据去重， 存储领域。在科研能力方面，我目前已经以第一作者发表顶级国际会议一篇，目前有一个CCFA类的期刊在投一篇。在项目方面，我在我导师的团队带领下，完成和华为未来实验室、海军工业大学等单位的合作项目。生活方面呢，我很喜欢运动，比如我经常去游泳，也是经常回去参加一些我们学校啊，市里举办的一些游泳比赛，虽然很少拿奖，但是我主要也是享受游泳这项运动。此外，我为人积极乐观，个人认为我是一个乐观主义者。

1.长安的企业文化是什么？

**创新、求变、百折不挠和担当前行**，而且既然我想要选择进入国企，就是准备好了奉献.

你了解长安的哪些汽车？深蓝、马自达、阿维塔

2.优点，缺点？

（1）工作经验还不足，是我曾经未涉及的领域。

（2）自信（善于在别人面前表现），面对困难可以冷静分析，做事情有条理

3.反问

（1）我们一共有几面？

（2）我如果加入，主要从事的业务是什么？

（3）我们这个面试大概多久会出结果？

4.你看重哪些？

平台未来的发展、与我专业技术是否相符、薪酬福利





1.项目中遇到过什么困难，怎么解决？

​	工程方面的困难，拿我的项目举例子，首先阅读源码是一个比较困难的工作，因为那个时候我才大三.....等等 。除了工程方面的困难，还有就是比如文献查找方面的困难，很多东西，你要搞创新，这些东西很多以前的文献里并没有，idea只能靠自己去想，通过阅读大量文献，总结别人的工作的优缺点，然后复现别人的工作，在这个过程中，不断有自己的思考，然后形成idea，再去落实它，去合理的验证它，这个过程是漫长切艰难的。解决的方法就是，在阅读文献形成idea的过程中要多去批判性思考，多问问你自己，作者为什么要这样做，这样做的好处是什么，可以带来多少的性能提升？我能否去借鉴作者的做法？我能否再他的基础上带来进一步的提高？

2.mt怎么评价你的？

​	mt觉得我的工程能力不仅仅于此。比如，他说有总共有10分的能力，他觉得我有12分的能力去突破当前的系统的性能瓶颈，去精益求精。

3.淘天的企业文化？
	用户为先、生态繁荣、科技驱动三大战略。

用户为先
	淘宝要做生活消费第一入口的国民App。淘宝将以“历史级的巨大投入”，为商家做大用户规模；持续升级用户产品、投入服务和物流建设，做好用户体验；一	切围绕喜欢、想看、爱看、爱玩等用户需求，提供更丰富的商品、短视频、直播、种草内容和人格化店铺。

生态繁荣
	淘宝被定位为一个人来人往、丰富有趣的街区，未来五年将汇聚上千万商家、上亿创作者和各种服务商。淘天集团新的组织机构，负责建设开放、普惠和共赢的生态，“不同赛道、各自精彩”。品牌业务发展中心将重点助力企业做好品牌、商品、用户的全周期建设、运营和发展，及运营全盘生意；中小企业发展中心服务创业者和中小商家，将重点建设超过20万家特色店铺。两大中心是一个相互联通的整体，共同支持商家走好从创业到中小企业再到品牌化的上升发展之路。平台还将陆续主动降低平台收费，增加平台商业化补贴，进一步降低商家经营成本。

科技驱动
	淘宝将举集团科技和数据能力，升级所有现有商家工具，并创造AI时代全新的用户产品和服务。未来五年内，淘宝将实现商家运营工具的全面智能化、最终为商家极大地降本、提效。

4.如何看待加班，对工作压力的看法？

​	淘天取得的成就也都有目共睹，既然我选择了淘天，就说明我愿意奋斗。而且我还年轻，多加班没有关系，我希望自己加班的时间能真正为公司创造价值，为自己的职业技能添砖加瓦。 自己在平时的科研中也比较能吃苦，我们组里的氛围也是要求我们尽自己最大的努力去展现自己的价值

5.你能给公司带来什么价值？
	我相信的科研能力和工程能力，研究生期间也收获的很多的成果，我的这能力已经在研究生期间得到了很好的锻炼，我会带着我的能力和努力，相信这部分能力会给淘天部门带来一定的价值

6.在工作中如何与人协调工作。

7.HR问你面过大厂吗，结果怎样

​	（过了还好说，没过就要问你理由了，所以直接说有，技术面都过了，在排序，不知道结果）

8.有大厂了还选择他们吗？我对滔天技术块挺感兴趣的，如果淘汰选择了我我一定也会选择淘天

9.HR问你有其他offer吗？目前没有

10.最困难的问题是什么，如何应对的？我觉得吧往往个人的困难一般都不是什么困难，团队的困难可能才是真的困难，如果团队遇到什么困难，需要我我一定会站出来分担。

11.领导交给你一个很重要但又很艰难的工作，你怎么去处理？

​	与领导进行详细的沟通，确保我完全理解任务的目标、优先级和期望的成果，以及截止日期，细分任务，风险评估，我会考虑最坏的情况，并预先规划解决方案。

12.你朋友对你的评价？

​	我的朋友都说我是一个可以信赖的人。因为，我一旦答应别人的事情，就一定会做到。如果我做不到，我就不会轻易许诺。我觉的我是一个比较随和的人，与不同的人都可以友好相处。在我与人相处时，我总是能站在别人的角度考虑问题。

13.未来的职业规划？
	未来1-2年 基础巩固与积累经验

​	未来3-5年 技能拓展与专业发展，深入研究某个领域

​	未来5-10年 能够在团队担任技术负责人并持续学习新技术

反问：实习的待遇是如何，工作时段是如何划分的。公司对新入公司的员工有没有什么培训项目，我可以参加吗，公司的晋升机制是什么样的





## 阿里巴巴实习网络研发

1. 介绍一下这个网络库：

XNET 是一个淘宝自研的新一代跨端 Networking-Library，其主要焦点有以下两部分：

● 网络协议：C++风格的API，支持「HTTP (HTTP/1.0、HTTP/1.1、HTTP/2、HTTP/3)」、「WebSocket」、淘宝自研「ACCS」协议的高性能网络数据传输库；

● 网络调度：通过内置淘宝自建HTTP-DNS系统「AMDC」, 支持集团内业务(域名、用户粒度)在多维度(地域、平台、版本、人群、运营商等)实现单元化、就近接入、灾容切流等方面的网络运维能力；

任何与互联网协议传输相关的事务都可以被视为XNET的业务范畴，但其承载的上层数据并不做处理，例如它对HTML或任何通过HTTP / WebSocket / ACCS 传输的具体内容不做了解，但它知道所有关于如何通过HTTP / WebSocket / ACCS 传输此类数据的信息。

2. 这个XNet网络库和okhttp有什么区别？

（1）这个网络库是会接入AMDC服务器（阿里自研的DNS端到端域名解析服务）。

也就是但在我们的实际使用场景中，相信大家或多或少都遇到过这种问题，打开一个网页发现被运营商强制插入了广告(内容劫持)，或者页面打不开(DNS劫持或者某个端口连不通)，「XNET」内建了端到端的「HTTP-DNS」 (AMDC)的功能，客户端通过「XNET」访问自己的服务可以解决经常遇到的这些问题。基于自建「HTTP-DNS」 系统(AMDC)，可以实现多维度(App、平台、版本、域名、用户比例等)策略来控制客户端连到哪个机房VIP、使用的协议(HTTP/1.x、HTTP/2、HTTP/3、是否加密等)、使用的端口等。比如某地机房断网、服务宕机或者触达容量峰值，基于「HTTP-DNS」的快速调度能力可实现流量实时热迁移到其他单元，避免服务不可用的情况；同时基于中心式调度，在流量起点(端侧)即可实现在针对服务的部署情况实现流量的均衡访问控制。

（2）此外他除了支持http的系列协议之外，还支持ACCS协议，WebSocket协议，http3协议。而okhttp只支持WebSocket协议和h1和h2

● WebSocket协议

WebSocket 协议是一种网络通信协议，它提供了一种在一个单独的持久连接上进行双向通信的机制。这个连接是在客户端和服务器之间建立的，并且连接保持打开状态，直到客户端或服务器决定关闭它为止。传统的HTTP请求是单向的，即客户端向服务器发送请求，然后服务器回应。WebSocket则提供了全双工的通信能力，允许服务器和客户端能够实时地互相发送消息。WebSocket 协议在2011年由IETF标准化为RFC 6455。

● ACCS协议

ACCS协议的全称是「阿里全双工连接协议」。其诞生的背景是传统的请求应答模式(HTTP)限制了无线业务的多样性，一个实时性更强的双向通道的业务需求越来越强烈，业务迫切希望能和用户产生实时的交互，展开各种形式的互动。单从协议视角看，它能力与WebSocket比较类似：一个单独的持久连接上进行双向通信的机制。但是与WebSocket最大的不同的是，该协议后端对应的是一个完整的接入层体系，它解决了在阿里&淘宝海量业务规模下长连接风暴 、网络的抖动造成的重连风暴等风险；实现了后端业务按重要度的隔离、ACCS长连集群和应用内API集群分离的架构；具备了连接--设备--用户的三级状态的管理能力。这套端到端的完整接入层体系使得ACCS在提供基础的传输协议能力之外，也让各业务方能够以低成本接入的同时实现通道的高可用。

（3）XNet是真正可以做到三端向上透出统一接口，无平台限制，而Okhttp仅限于Android平台。

3. 那你主要负责哪一部分？

我主要负责是他们的BenchMark工程。XNet作为淘宝自研的一款跨平台网络库，其核心目标是通过高效、稳定的通信机制满足移动端对低延迟、高并发、多协议支持的需求。XNet目前处于开发阶段，其核心能力已初步完成鸿蒙端和iOS端的实现，而Android端仍在开发中。需通过制定系统的性能基准指标以全面评估并验证其能力边界，并支撑开发团队进行针对性优化。

因此，构建一个面向Android端的XNet性能基准测试工程，成为确保其能力与鸿蒙/iOS端对齐、满足业务需求的关键环节。该工程的指标涵盖资源指标和网络指标两大方面，其中资源指标包含CPU、内存、磁盘和电量核心指标，网络指标包含请求各阶段耗时和网络吞吐两大指标，实现端侧性能基准测试工程的全面覆盖。

价值：网络库作为淘宝App的流量基石，对稳定性、可靠性有着极高的水位要求，如何平稳安全的把当前手淘iOS/Android 上的网络库迁移到新一代跨平台C++ XNET, 是一件非常有挑战的事情。线下充分的Benchmark验证，为实现多端的网络库能力的对齐提供了坚实的保障。





4. 那你用到了哪些技术？

一个是端侧自动化测试工具，叫TMQlab这个是阿里自研的手机应用性能测试工具，他可以测试应用的各种资源开销如cpu,mem,net，power

5. 你负责了哪些需求的开发？

缓存查询这一块的开发：

下面的代码就是XNHttpSession::send的代码，在请求上下文创建完毕后，接下来就是查询缓存是否开启。如果开启缓存选项，则查询缓存并返回结果，否则请求服务器。

```c++
Int64 XNHttpSession::send(const XNHttpRequestRef &requestRef, XNHttpSessionListenerRef &listener) {

  if (nullptr == requestRef.get() || false == requestRef->isValid()) {
    XNLOGE("R[-1] send FAILED with INVALID request", 0);
    return kXNInvalidRequestID;
  }
  if (!XNEntry::isInitialized()) {
    XNLOGE("R[%d] send FAILED with UNINIT", requestRef->getID());
    return kXNInvalidRequestID;
  }
  XNHttpRequestContext::updateScheme(requestRef);
    
  XNHttpRequestContextRef requestContextRef =
    XNHttpRequestContext::create(requestRef, listener, requestRef->getRetryAvailable());
  Int64 requestId = requestContextRef->ID();

  if (requestRef->enableHttpCache() && requestContextRef->processRequestCache()) {
    XNLOGI("[http_cache] R[%d] hit cache", requestId);
    return requestId;
  }

  if (XNSessionPool::instance()->sendRequest(requestContextRef)) {
    return requestId;
  } else {
    return kXNInvalidRequestID;
  }
}

下面是requestContextRef->processRequestCache()处理缓存的实现。

bool XNHttpRequestContext::processRequestCache(void) {
  _cache = XNHttpCache::instance()->cachedResponseForRequest(this->getHttpRequest());
  XNLOGI("[http_cache] R[%d] cache code:%d", _id, _cache->code);
  // 禁止cache、未命中或者缓存过期
  if (_cache->code == kXNCacheForbid || _cache->code == kXNCacheNone || _cache->code == kXNCacheExpired) {
    if (_cache->code == kXNCacheForbid) {
      _cache = nullptr;
    }
    return false;
  }
  _haveCache = true;
  // 命中缓存，直接返回上层
  if (_cache->code == kXNCacheHit) {
    _responseRef = XNHttpResponse::create(_requestRef, _cache->response->code, true);
    if (nullptr == _responseRef) {
      XNLOGE("[http_cache] R[%d] create cache response fail, force not cache", _id);
      _cache->code = kXNCacheNone;
     	return false;
    }
    _handler->post([request = shared_from_this()]() {
     XNRecursiveLock _lock(request->_state_mutex);
    request->responseCache();
   });
   return true;
  }
  // 命中但已经过期需要验证
  XNLOGD("[http_cache] R[%d] hit cache, revalidate", _id);
  return false;
}
```

流程如下：

开始

├─ 获取缓存结果

│  └─ _cache = XNHttpCache::cachedResponseForRequest()

├─ 记录缓存状态码

│  └─ XNLOGI("[http_cache] R[%d] cache code:%d")

├─ 判断缓存是否可用

│  ├─ 禁止缓存(kXNCacheForbid) → _cache = nullptr → 返回 false

│  ├─ 未命中(kXNCacheNone) → 返回 false

│  └─ 缓存过期(kXNCacheExpired) → 返回 false

└─ 缓存命中(kXNCacheHit)

  │

  ├─ 创建响应对象

  │  └─ _responseRef = XNHttpResponse::create()

  │    └─ 若创建失败 → 记录错误 → _cache->code = kXNCacheNone → 返回 false

  ├─ 异步执行 responseCache() 回调

  │  └─ _handler->post([request] { request->responseCache(); })

  └─ 返回 true

我们通过源码可以知道_cache的数据结构是XNHttpCacheResultRef。其结构如下。

其中包含了两部分。

  ○ 一部分是错误状态码，包含5个状态，分别表示禁止缓存、缓存未命中、缓存命中、缓存过期和缓存需要重新验证。

  ○ 另一部分是缓存的响应数据。包含状态码、响应头、响应体、缓存过期时间和pie json格式（这个知道是什么东西，应该是底层pie设置的标志）

```c++
enum XNCacheErrorCode {
  kXNCacheForbid = 0, // Cache 禁止
  kXNCacheNone,    // Cache 没命中
  kXNCacheHit,    // Cache 命中
  kXNCacheExpired,  // Cache 过期
  kXNCacheRevalidate // Cache 需要 revalidate
};

class XNHttpCacheResponse {
public:
  XNHttpCacheResponse() {}
  ~XNHttpCacheResponse() {}
  UInt32 code;
  pie::JSON headers;
  std::string body;
  long long expireTime;
  pie::JSON vary;
};

typedef std::shared_ptr<XNHttpCacheResponse> XNHttpCacheResponseRef;

class XNHttpCacheResult {
public:
  XNCacheErrorCode code;
  XNHttpCacheResponseRef response;
};
typedef std::shared_ptr<XNHttpCacheResult> XNHttpCacheResultRef;
```

那么在了解缓存本身的数据结构后，就有一个问题，缓存是如何生成的？

接下来我们来看cachedResponseForRequest的实现流程图（代码太长直接上总结）：

开始

│

├─ 创建缓存结果对象（_cache）

├─ 检查缓存服务是否可用

│  └─ 不可用 → cache->code = kXNCacheForbid → 返回

├─ 生成缓存键（cacheKey）

│  └─ 无效 → cache->code = kXNCacheForbid → 返回

├─ 检查请求头 Cache-Control 是否包含 no-store 字段

│  └─ 包含 → 删除缓存 → cache->code = kXNCacheForbid → 返回

├─ 从缓存中查找缓存值（cacheValue）

│  └─ 未找到 → cache->code = kXNCacheNone → 返回

│

├─ 解析缓存值为 JSON

│  │

│  ├─ JSON 结构不合法 → 删除缓存 → cache->code = kXNCacheNone → 返回

│  ├─ 版本不匹配 → 删除缓存 → cache->code = kXNCacheNone → 返回

│  └─ 解析成功 → 继续

├─ 检查 Vary 字段是否匹配

│  └─ 不匹配 → 删除缓存 → cache->code = kXNCacheNone → 返回

├─ 判断缓存是否过期

│  │

│  ├─ 未过期且请求/响应未禁用缓存 → cache->code = kXNCacheHit → 返回

│  │

│  └─ 已过期 → 检查协商字段（ETag/Last-Modified）

│    ├─ 存在 ETag → 设置 If-None-Match → cache->code = kXNCacheRevalidate → 返回

│    ├─ 存在 Last-Modified → 设置 If-Modified-Since → cache->code = kXNCacheRevalidate → 返回

│    └─ 无协商字段 → cache->code = kXNCacheExpired → 返回

└─ 异常处理

  └─ 捕获异常 → 记录错误 → 删除缓存 → cache->code = kXNCacheNone → 返回

阅读源码可知，底层缓存调用的是已经封装好的pie的缓存服务，需要删除缓存时就直接调用相关接口。总结来说任何异常（如 JSON 解析失败）产生，就记录错误，删除缓存，返回 kXNCacheNone。如果缓存未过期就返回缓存数据，如果已经过期，则将缓存状态标记为已过期，然后返回结果。如此来看，在XNHttpRequestContext::processRequestCache的实现中，只有缓存命中且未过期才能正常返回。

6.你觉得这个东西还有什么可以改进的地方？





## FinerDedup

1.远程开发的问题：NFS挂在服务器和本地windows。
2.很有意思的一点是Android加密
3.写拦截，由于Android源码没有write函数，是bionic中的write函数是以汇编方式呈现，Write.S也只是根据write系统调用号陷入内核。我们通过将Write.S修改为\__Write.S，然后将write函数替换为C写的函数，在用C写的write函数中再调用\_\_write函数，相当于为汇编文件套了一层壳，这样所有写操作都会经过c写的write函数，实现拦截的目的

4.模型出错了怎么办？



在libc层拦截写操作，收集写trace，生成模型以及后续推理传递标签

传递标签主要分为两个部分 ： 用户态到内核，文件系统到通用块层

用户态到内核态：在修改了libc的write函数后，我们使用模型对标签进行了推理。当数据写到page cache的时候，写调用才算完成。因此我们分析了写调用栈，逐步修改函数调用参数将标签传递，最后将标签保存在page cache结构中

文件系统到块层：接下来文件系统会将page cache的内容异步写入磁盘中，中间过程不在叙述，最终会调用\__submit_bio()，因为我们可以通过BIO结构体将标签传递到块层

内核：主要由指纹表，bloom过滤器组成

两种容错机制：

预测为重复，添加到指纹表，定期清除

预测为非重复，实际为重复，经过bloom过滤器，添加到指纹表



问题1：写拦截，由于Android源码没有write函数，是bionic中的write函数是以汇编方式呈现，Write.S也只是根据write系统调用号陷入内核。我们通过将Write.S修改为\__Write.S，然后将write函数替换为C写的函数，在用C写的write函数中再调用\_\_write函数，相当于为汇编文件套了一层壳，这样所有写操作都会经过c写的write函数，实现拦截的目的

## 基于OpenHarmony的分布文件去重

本项目在OpenHarmony上部署了一个带中心节点的分布式文件级去重系统。

**用户态：**

每个设备作为客户端，分别扫描分布式目录下的文件，记录指纹、文件名。分别将这些条目发送给服务器端，服务器整个所有客户端发送的条目做全局去重，提高去重率，为每个客户端分配一个线程，并发的去重，使用读写锁保护哈希表。

服务端全局表的作用：

- **全局去重管理**：汇总所有客户端发送的文件指纹信息，识别和记录全局唯一的文件。
- **唯一文件定位**：记录每个唯一文件的存储位置（即哪个节点保存了该文件的副本）。
- **引用管理**：跟踪每个唯一文件被多少个客户端引用，以便于引用计数和文件生命周期管理。
- **元数据管理**：维护与文件相关的元数据，如文件名、大小、创建时间等，便于文件的管理和检索。
- **分发重删信息**：向各客户端分发重删信息，指导客户端如何处理本地重复文件（如创建重删文件、更新硬链接表等）。

对于重复的文件，服务端会将重复文件唯一存在的文件路径发送给需要删除文件的设备。客户端会维护重删表和一个硬链接表。主要是负责文件远程重定向和维护每个设备上的唯一文件的硬链接和引用计数。

**1.重删表**

#### **作用**

重删表的主要作用是记录每个节点上被识别为重复的文件及其对应的唯一源文件的位置。通过维护重删表，系统能够在文件被访问或操作时，快速查找并重定向到唯一的源文件，从而实现透明的文件访问和管理。

#### 内容

重删表通常包含以下信息：

- **重复文件路径**：在当前节点上被标记为重复的文件的完整路径。
- **唯一文件路径**：对应的唯一源文件在某个节点上的完整路径。
- **源节点标识**：存储唯一文件的节点标识（如节点ID、IP地址等），用于定位唯一文件所在的设备。
- **去重时间戳**（可选）：记录文件去重的时间，以便于管理和调度。
- **其他元数据**（可选）：如文件大小、指纹哈希值等，用于进一步验证和管理。

![QQ_1737893677010](C:\Users\24992\AppData\Local\Temp\QQ_1737893677010.png)

**2.硬链接表**

#### **作用**

硬链接表用于管理每个节点上创建的硬链接，确保多个路径指向同一个物理文件。通过维护硬链接表，系统能够准确跟踪每个唯一文件的引用数量，确保在引用计数为零时安全删除文件，避免数据丢失。

#### **内容**

硬链接表通常包含以下信息：

- **唯一文件路径**：在当前节点上唯一源文件的完整路径。
- **硬链接路径列表**：指向该唯一文件的所有硬链接的完整路径列表。
- **引用计数**：当前唯一文件被引用的次数，即硬链接的数量。
- **文件元数据**（可选）：如文件大小、指纹哈希值等，用于验证文件的一致性。

![QQ_1737893820974](C:\Users\24992\AppData\Local\Temp\QQ_1737893820974.png)

**3.远程读写**

拦截系统调用：

- 使用`LD_PRELOAD`机制加载自定义的共享库，该库覆盖libc的`read`和`write`函数。
- 当应用程序调用`read`或`write`时，实际上调用的是自定义库中的函数。

识别重删文件：

- 自定义`read`和`write`函数，inode的i_flags标志位添加一个新的标志位S_DEDUP，代表该文件是重删文件

根据文件状态，自定义`read`和`write`函数决定是进行本地操作还是远程操作：

- 本地文件：如果文件未被去重（即本地存在唯一副本），直接调用原始的libc `read`或 `write`函数。
- 重删文件：如果文件被标记为重删，执行远程操作。

**read过程**：

- 如果与服务器的连接尚未建立，创建一个持久的TCP连接（例如，连接到服务器的IP和端口）。

- 维护一个连接池或持久连接以减少连接开销。

- 发送读取请求：包括唯一文件的标识、读取的偏移量和字节数。

  服务器处理请求：从唯一文件中读取指定范围的数据并发送回客户端。

  客户端接收数据：动态库将接收到的数据复制到用户缓冲区，并返回实际读取的字节数给应用程序。

**write过程**：

获取唯一文件路径：从重删表中获取唯一文件所在的远程路径（如`Node_A:/data/unique/report.docx`）。

然后会复制唯一文件到本地：

- 发送复制请求：动态库通过socket向服务器请求将唯一文件复制到本地。
- 服务器处理复制请求：将唯一文件的内容发送给请求的客户端节点。
- 客户端接收并保存文件：动态库在本地创建新的唯一文件副本，保存到本地路径（如`/data/docs/report.docx`），并更新本地的硬链接表和重删表。
- 解除重删标记：将文件从重删状态解除，成为本地的唯一文件。
- 更新全局去重表：客户端向服务器报告该文件现在在本地有一个唯一副本，服务器更新全局去重表，反映这一变化。



**内核：**

内核模块：创建一个删除的同名文件，并将唯一源文件的硬链接的路径写入（类似于软连接，后续文件系统会用）。并设置inode的i_flags标志位添加一个新的标志位S_DEDUP，代表该文件是重删文件。读写时获取底层文件系统的inode判断是否是重删文件，如果是，那么直接获取文件中的内容即软链接的路径，然后进一步通过远程打开文件，实现重定位。



## 跨平台全文检索系统FileWhole

本项目开发了一款高效的轻量化全文检索软件FileWhole，传统方案（例如Docfetcher、Everything）对非文本文件（代码/图片/音频等）支持不足，检索延迟高，代码未开源，无法国产化。FileWhole软件支持广泛的文件格式，包括常用的文档类型（如DOC、PPT、PDF等）、编程语言代码类型（如 C、Python等）、及图片类型（如 PNG、JPEG等）以及音频类型（如MP3、MP4等）。

FileWhole主要使用Electron桌面应用框架开发，核心是基于合SQLite FTS5扩展实现全文检索功能。在文件内容解析方面，使用到了Apache Tika作为传统文档的解析工具，使用nodejs中的第三方库(tesseract.js)实现图片OCR文字内容提取操作，使用（whisper-node/ffmpeg）实现音频格式转化和文字内容提取。

平台兼容性方面我们支持主流操作系统，例如Window7 , Windows10,Windows11,国产操作系统，例如麒麟。

#### 主要技术

**1.Electron**

- **介绍**：Electron 是一个开源框架，可以让开发者使用 Web 技术（如 HTML, CSS, JavaScript）开发桌面应用程序。它的核心是结合了 Chromium 浏览器引擎和 Node.js ，因此你可以用 Web 技术开发跨平台的桌面应用，同时也能访问操作系统的本地资源。
- **在项目中的作用**：在 FileWhole 中，Electron 作为桌面应用的框架，确保了应用能够在多平台上运行，同时可以利用 Node.js 的能力执行后台逻辑，如文件解析、搜索等操作。

**2.SQlite FTS5**

- **介绍**：SQLite 是一个轻量级的关系型数据库，FTS5（全文搜索扩展）是其一个扩展，提供了对文本字段的全文索引功能，能够快速检索大量的文本数据。FTS5 使用反向索引技术，提高了文本检索效率。

- **在项目中的作用**：FileWhole 使用 SQLite 的 FTS5 扩展来实现高效的全文检索功能。无论是文档文件中的内容，还是从图像、音频等其他文件格式中提取出的文本数据，都会存储在 SQLite 数据库中，供后续快速检索。

- **原理：**

  ​	**反向索引（Inverted Index）**：FTS5 使用反向索引技术，类似于大多数全文搜索引擎（如 Elasticsearch、Solr）使用的技术。反向索引将文本中的词汇（例如 "apple", "banana", "orange"）与包含这些词的文档关联起来。每个词会指向一个包含该词的文档的列表。这样，当你进行搜索时，数据库不需要扫描整个文档，而只需要查找相关的词汇索引即可。

  ​	**分词和标记（Tokenization）**：FTS5 会将文本内容分解为一个个词（或标记），并将这些词存储在索引中。FTS5 使用不同的分词算法来处理不同的语言和文本格式，确保可以正确处理文本中的词语。

  ​	**查询执行**：当用户进行搜索时，FTS5 会快速查找词汇在反向索引中的位置，并返回相关文档的 ID。然后，你可以根据这些 ID 查询原始表（如 `t_content` 表）中的详细信息。

  ​	**性能优化**：FTS5 支持各种性能优化功能，如增量更新、自动优化索引、支持排序等。它的设计目标是处理大量文本数据时仍能提供高效的查询性能。

**3.Apache Tika**

- **介绍**：Apache Tika 是一个开源的内容分析工具，能够自动识别和提取多种文件格式中的内容。支持的文件类型包括文本文件、办公文档（如 Word, Excel）、PDF、HTML 以及许多其他格式。
- **在项目中的作用**：FileWhole 使用 Apache Tika 来解析传统文档格式（如 DOC、PPT、PDF 等），提取其中的文本内容，为后续的全文检索提供数据。

**4.tesseract.js**

- **介绍**：Tesseract.js 是一个基于 Tesseract OCR 引擎的 JavaScript 库，用于图像的文字识别（OCR）。它可以从图像中提取出文字信息，支持多语言识别。
- **在项目中的作用**：FileWhole 使用 tesseract.js 来实现对图片文件（如 PNG、JPEG 等）中的文字内容的提取。图像的 OCR 处理使得 FileWhole 能够支持图片中的文本检索。

**5.whiper-node**

- **介绍**：whisper-node 是一个基于 OpenAI Whisper 模型的 Node.js 库，Whisper 是一种深度学习模型，专门用于语音转文本的任务。它支持多种语言的语音识别。
- **在项目中的作用**：FileWhole 使用 whisper-node 处理音频文件（如 MP3、MP4 等），将音频中的语音转化为文本。音频文件的转化和文字内容提取后，能够为用户提供基于音频的检索功能。

**6.FFmpeg**

- **介绍**：FFmpeg 是一个开源的音视频处理工具，支持对音视频文件的格式转换、流处理、剪辑等操作。它能够处理几乎所有类型的音视频格式。
- **在项目中的作用**：FileWhole 使用 FFmpeg 来处理音频文件的格式转换，例如将不同格式的音频文件转为统一的格式，以便进一步提取音频中的文字内容。

#### 体系架构

**1. 数据库结构概述** 在 FileWhole 中，文件内容被存储在多个数据库文件中，每个数据库对应不同类型的文件，具体包括：

- **文档库** (`document.sqlite`)
- **图片库** (`picture.sqlite`)
- **视频库** (`video.sqlite`)
- **音频库** (`audio.sqlite`)
- **压缩库** (`compress.sqlite`)
- **代码库** (`code.sqlite`)
- **执行库** (`execute.sqlite`)

**2. 核心表格结构**

以下是关键数据库表的作用和结构：

**t_content**：该表用于存储文件的基本信息及其提取的内容。包括文件的 ID、文件内容、文件名、文件扩展名等。`rid` 是主键，用于唯一标识每个记录。

- `id`: 文件的唯一标识符
- `content`: 存储从文件中提取的文本内容
- `file_name`: 文件的名称
- `ext`: 文件扩展名
- `hack`: 一个额外的字段，用于存储额外的内容信息
- `rid`: 唯一的行ID，用于引用该记录

**t_content_idx**：该表为 `t_content` 表提供全文检索功能。通过 FTS5（全文搜索扩展）提供高效的文本检索功能，支持快速查找文件中的内容。

**t_file**：该表用于存储文件的详细信息，例如文件大小、修改时间、MD5 校验和、文件状态等。这些信息有助于跟踪文件的状态和版本控制。

- `internal_id`: 内部的唯一标识符
- `id`: 文件的唯一标识符
- `file_name`: 文件名称
- `content`: 文件内容
- `size`: 文件大小
- `ext`: 文件扩展名
- `modify_time`: 文件的最后修改时间
- `md5`: 文件的 MD5 校验值，用于验证文件完整性
- `duplicate`: 文件是否为重复文件
- `content_status`: 文件内容的状态
- `tags`: 相关标签
- `create_time`: 文件的创建时间

**t_error**：用于存储文件索引过程中的错误信息。当文件在索引过程中出错时，错误信息会被记录在此表中，便于后续的处理。

**t_all**：该表记录所有已处理的文件名。用于保持一个文件列表，便于后续的操作。

**t_index**：该表用于存储索引的统计信息，例如文件的总数、成功索引的文件数、出错文件数、索引的大小等。这些信息有助于监控索引的状态和性能。

- `path`: 文件路径
- `all_file_count`: 总文件数
- `success_file_count`: 成功索引的文件数
- `error_file_count`: 错误文件数
- `index_size`: 索引的大小
- `create_time`: 索引创建时间
- `update_time`: 索引更新时间
- `status`: 索引状态

**3. 数据库触发器**

FileWhole 使用了多个触发器来保证数据的一致性和完整性：

- **t_content_ai**：在插入 `t_content` 表数据时触发，自动将数据插入到 `t_content_idx` 表中，确保全文检索表的更新。
- **t_content_ad**：在删除 `t_content` 表的数据时触发，自动删除对应的索引数据和文件记录。
- **t_content_au**：在更新 `t_content` 表数据时触发，首先删除旧的数据索引，然后插入新的数据到索引表。

### **为何 FTS5 表需要绑定一个传统的表格**？

FTS5 表是一个“虚拟表”，它并不直接存储数据，而是通过绑定到一个传统表（如 `t_content`）来存储和查询数据。创建 FTS5 表时需要绑定一个传统表格的原因如下：

- **数据存储和映射**：FTS5 表仅存储文本数据的反向索引信息，而不是文件的所有内容。因此，它需要绑定到一个传统表格（例如 `t_content`），以便存储原始数据。传统表（如 `t_content`）存储了文件的元数据、内容、文件名等信息，而 FTS5 表只是提供了对文本数据的索引功能。通过这种绑定，FTS5 表可以快速定位到相应的记录，而无需重复存储所有原始内容。
- **全文搜索与数据存储分离**：将 FTS5 表与传统表分离是一种常见的优化设计。在大规模数据检索时，全文索引可以显著提高查询速度，但索引表本身不适合存储实际数据。传统表可以存储更复杂的数据结构和元数据，而 FTS5 表专注于加速文本检索，保持数据库设计的清晰和高效。
- **一致性和触发器**：通过绑定一个传统表，FTS5 能够确保当传统表的内容发生变化时（如插入、更新或删除数据），相应的索引也会同步更新。触发器（如 `t_content_ai`, `t_content_ad`, `t_content_au`）帮助在数据发生变化时自动同步到 FTS5 表，确保索引的准确性。

### 如何索引中断恢复？

在构建索引前，使用fastglob库扫盘，获取全局文件列表，保存到系统数据库中。

索引构建的过程即是从全局文件列表读取文件路径并插入FTS5表的过程，每构建一条索引则更新一次文件的元数据表，则文件元数据表里有的条目，就代表改该文件已经被建立索引。

当中断发生后，软件重启时会读取全局文件列表，和文件元数据表中的文件，比较两者的数量，如果不同，则表示上次索引建立时发生中断，则从剩余的全局文件列表中的文件继续建立索引。

### FTS5的原理了解吗？







## 多设备协同去重

本项目说在OpenHarmony的HMDFS分布式文件系统上实现的文件级去重

用户态：

每个设备作为客户端，分别扫描分布式目录下的文件，记录指纹、文件名。分别将这些条目发送给服务器端，服务器整个所有客户端发送的条目做全局去重，提高去重率，为每个客户端分配一个线程，并发的去重，使用读写锁保护哈希表。

对于重复的文件，客户端重复文件的路径和唯一存在的文件路径发送给需要删除文件的设备，即重删表。和一个硬链接表，主要是维护每个设备上的唯一文件的硬链接和引用计数，给唯一文件做硬链接并维护引用计数。



内核：

内核模块：创建一个删除的同名文件，并将唯一源文件的硬链接的路径写入（类似于软连接，后续文件系统会用）。并设置inode的i_flags标志位添加一个新的标志位S_DEDUP，代表该文件是重删文件。

文件系统：由于HMDFS是一个堆栈文件系统，他在正常文件系统之上，VFS之下。因此在VFS获取到HMDFS的file结构体后， 是HMDFS进一步对底层文件系统进行的操作。HMDFS获取底层文件系统的inode判断是否是重删文件，如果是，那么直接获取文件中的内容即软链接的路径，然后进一步打开文件，将该文件作为HMDFS操作的底层文件，实现重定位。

在分布式文件系统中，没有提供软连接和硬链接的操作。实现类似软连接的操作是因为可以跨设备的访问分布式文件系统的文件。在本地文件系统做硬链接是为了让重定位的文件与源文件实现部分的解耦，如源文件的重命名或者删除等操作。



## XV6

XV6是什么类型的操作系统介绍一下，是否是实时操作系统

XV6是一个RISC-V架构的类unix操作系统，并不是实时操作系统，



系统调用

添加系统调用号，添加系统调用定义，

sys_trace 用掩码表示要追踪的系统调用号，最多可以追踪32个，比如100就是追踪第三个 即当num是3时， 1 << num & mask为1，即需要进行追踪，从陷阱帧（trapframe）中保存的`a7`中检索系统调用号，`a0`存储返回值



进程管理

用户级线程的切换

只需要一个类似context的结构来保存上下文





内存管理

Xv6有一个单独的用于在内核中执行程序时的内核页表。内核页表直接映射（恒等映射）到物理地址，也就是说内核虚拟地址`x`映射到物理地址仍然是`x`。Xv6还为每个进程的用户地址空间提供了一个单独的页表，只包含该进程用户内存的映射，从虚拟地址0开始。因为内核页表不包含这些映射，所以用户地址在内核中无效。因此，当内核需要使用在系统调用中传递的用户指针（例如，传递给`write()`的缓冲区指针）时，内核必须首先将指针转换为物理地址。本节和下一节的目标是允许内核直接解引用用户指针。



你的第一项工作是修改内核来让每一个进程在内核中执行时使用它自己的内核页表的副本。修改`struct proc`来为每一个进程维护一个内核页表，修改调度程序使得切换进程时也切换内核页表。对于这个步骤，每个进程的内核页表都应当与现有的的全局内核页表完全一致。



本实验是实现将用户空间的映射添加到每个进程的内核页表，将进程的页表复制一份到进程的内核页表就好。



惰性分配

1. 申请内存时，`sbrk()`不分配物理内存，只增加对应的虚拟内存大小。
2. 当发生缺页中断（page fault）时，再进行内存分配



COW

1. 增加引用计数：首先，为每个物理页增加引用计数，记录有多少个虚拟页面指向该物理页。分配内存时初始化为1，kfree时减1，直到0时才回收
2. 修改fork函数，使得子进城和父进程共享页面，清除PTE_W，添加COW标志，使得页面变为只读，增加引用计数
3. 处理页错误，如果由于写操作导致的页面错误且页面标记为 COW，如果页面引用计数为1，说明只有这个页面引用该物理页面，那么直接添加写标志位。如果不为1，那么分配新的物理内存，将原来的物理页面的引用计数减1，并标记为可写



xv6中的`fork()`系统调用将父进程的所有用户空间内存复制到子进程中。如果父进程较大，则复制可能需要很长时间。更糟糕的是，这项工作经常造成大量浪费；例如，子进程中的`fork()`后跟`exec()`将导致子进程丢弃复制的内存，而其中的大部分可能都从未使用过。另一方面，如果父子进程都使用一个页面，并且其中一个或两个对该页面有写操作，则确实需要复制。

copy-on-write (COW) fork()的目标是推迟到子进程实际需要物理内存拷贝时再进行分配和复制物理内存页面。

COW fork()只为子进程创建一个页表，用户内存的**PTE指向父进程的物理页**。COW fork()将父进程和子进程中的所有用户PTE标记为**不可写**。当任一进程试图写入其中一个COW页时，CPU将**强制产生页面错误**。内核页面错误处理程序检测到这种情况将为出错进程分配一页物理内存，将原始页复制到新页中，并修改出错进程中的相关PTE指向新的页面，将PTE标记为可写。当页面错误处理程序返回时，用户进程将能够写入其页面副本。

COW fork()将使得释放用户内存的物理页面变得更加棘手。给定的物理页可能会被多个进程的页表引用，并且只有在最后一个引用消失时才应该被释放。（添加引用计数）



反向映射：

通常，页表（Page Table）提供的是从虚拟地址到物理地址的映射，即给定一个虚拟地址，可以通过页表找到对应的物理页帧。然而，在某些情况下，操作系统需要反向操作：给定一个物理页帧，找到所有映射到它的虚拟地址。这就是反向映射的用途。

**第一个场景是内存回收**，内存不足时内核会从不活跃的lru链表尾部回收一些页面，而对于映射到进程地址空间的物理页面，我们需要在回收之前对他做解除映射处理。

对于匿名页，由于里面的数据是进程运行过程中产生的有用数据，不能随意丢弃，需要交换到交换分区，然后通过反向映射查找映射这个物理页的每个页表项，然后将页表项修改为换出页标识符（通过它能知道匿名页被交换到哪个交换分区，哪个位置）。再次访问匿名页时通过换出页标识符即可将所需的数据页从交换分区换入再建立页表映射即可。

而对于文件页，如果是“干净的”文件页，是可以直接丢弃回收。由于文件页有后备文件支持，再次访问文件页时，将所需的数据页从文件中读取到内存建立页表映射即可。

**第二个场景是页面迁移**，页面迁移在内核的CMA、内存碎片整理等被广泛使用。在迁移页面的时候，如果是映射页，会调用try_to_unmap将映射这个物理页的每个页表项修改为迁移类型表项。迁移过程中，进程再次访问会发生swap缺页异常，异常处理中判断为迁移类型表项就会是进程睡眠等待迁移完成。



mmap怎么实现的

1. 添加mmap和munmap的系统调用

2. 定义vma结构体（虚拟内存区域结构体），并添加到进程结构体中，从文件的文件偏移与虚拟地址的起始地址开始对应

   ```c
   #define NVMA 16
   // 虚拟内存区域结构体
   struct vm_area {
     int used;           // 是否已被使用
     uint64 addr;        // 起始地址
     int len;            // 长度
     int prot;           // 权限
     int flags;          // 标志位
     int vfd;            // 对应的文件描述符
     struct file* vfile; // 对应文件
     int offset;         // 文件偏移，本实验中一直为0
   };
   
   struct proc {
     ...
     struct vm_area vma[NVMA];    // 虚拟内存区域
   }
   
   ```

3. 实现mmap，分配一个未使用的vma，惰性分配虚拟内存，增加文件的引用计数，防止文件被删除

4. 处理缺页错误，当访问对应的虚拟地址时，会出现缺页错误：分配物理页面，将文件内容读到物理页面中，添加虚拟地址和物理地址的映射关系

5. 实现munmap，将对应的vm_area标记为未使用，释放物理内存，更新页表，将对应页面写回磁盘

6. 修改exit，当进程退出，将进程的已映射区域取消映射



锁

哈希桶+双链表

bget的时候，分配方式是优先从当前列表遍历，找到一个没有引用缓冲区，如果没有就申请下一个桶的锁，并遍历该桶，找到后将该缓冲区从原来的桶移动到当前桶中，最多将所有桶都遍历完。

### Buffer Cache 的作用

1. **减少磁盘访问次数**：缓冲区缓存存储了最近访问的磁盘块数据，避免了频繁的磁盘 I/O 操作，提高了系统性能。
2. **提高文件系统性能**：缓存的磁盘块数据可以快速地提供给请求者，从而加速文件的读写操作。
3. **数据一致性**：通过缓冲区缓存，可以确保对磁盘块的修改先在内存中进行，并在适当的时机写回磁盘，保证数据的一致性。
4. **并发控制**：缓冲区缓存可以提供必要的同步机制，防止多个进程同时访问或修改同一磁盘块，保证文件系统的正确性。

### 为什么选择哈希表加双向链表的优化？

在 xv6 中，缓冲区缓存采用了哈希表加双向链表的结构。这种结构的选择有以下几个原因：

1. **查找效率高**：哈希表可以快速定位缓冲区块，实现 O(1) 的平均查找时间，从而快速找到所需的缓存块。
2. **缓存替换策略**：双向链表可以方便地实现 LRU（Least Recently Used）替换策略，将最近使用的缓冲区块移动到链表头部，最不常用的缓冲区块移动到链表尾部，以便在需要时进行替换。
3. **简单且高效**：哈希表加双向链表的结构相对简单，容易实现和维护，同时也能提供较高的性能。

### 为什么不用树结构？

树结构（如平衡树、红黑树等）在某些情况下可以提供较高的查找性能和有序性，但在缓冲区缓存的场景中，不使用树结构的原因主要有以下几点：

1. **实现复杂度**：树结构的实现和维护比哈希表加双向链表要复杂得多，涉及到插入、删除和调整操作，对于一个教学目的的操作系统（如 xv6）来说，简单性和易读性更重要。
2. **查找性能**：尽管树结构可以提供 O(log n) 的查找性能，但哈希表的平均查找时间是 O(1)，在大多数情况下查找性能更优。
3. **缓存替换策略的实现**：双向链表自然适合实现 LRU 替换策略，通过将最近使用的缓冲区块移动到链表头部，可以简单高效地实现 LRU。而树结构实现 LRU 替换策略相对复杂，维护节点的访问顺序需要额外的开销。
4. **内存开销**：树结构通常需要额外的指针或结构体来维护平衡和有序性，相比之下，哈希表和双向链表的内存开销更小。

文件系统



