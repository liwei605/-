# MYSQL

## MYSQL基本语法

**建库**

```sql
CREATE DATABASE database_name;
```

**建表**

```sql
CREATE TABLE table_name (
    column1 datatype constraints,
    column2 datatype constraints,
    ...
    PRIMARY KEY (column_name)
);
```

常用的数据类型分为三大类：数值、日期/时间、字符串

1. **数值类型**

- **TINYINT**: 小整数，范围为 -128 到 127（有符号），0 到 255（无符号）。
- **INT**: 标准整数，范围为 -2,147,483,648 到 2,147,483,647（有符号），0 到 4,294,967,295（无符号）。
- **BIGINT**: 大整数，范围为 -9,223,372,036,854,775,808 到 9,223,372,036,854,775,807（有符号），0 到 18,446,744,073,709,551,615（无符号）。
- **FLOAT**: 单精度浮点数，适用于不需要高精度的小数。
- **DOUBLE**: 双精度浮点数，适用于需要更高精度的浮点数。
- **DECIMAL(M, D)**: 定点数，精确的小数，例如货币计算。`M` 是总位数，`D` 是小数位数。

2. **日期和时间类型**

- **DATE**: 存储日期，格式为 `YYYY-MM-DD`。
- **TIME**: 存储时间，格式为 `HH:MM:SS`。
- **DATETIME**: 存储日期和时间，格式为 `YYYY-MM-DD HH:MM:SS`。
- **TIMESTAMP**: 存储时间戳，自动记录插入或更新时间，格式为 `YYYY-MM-DD HH:MM:SS`。
- **YEAR**: 存储年份，格式为 `YYYY`。

3. **字符串类型**

- **CHAR(M)**: 固定长度的字符串，最大长度为 255 字符。
- **VARCHAR(M)**: 可变长度的字符串，最大长度为 65,535 字符（受表行大小限制）。
- **TEXT**: 可变长度文本，最大存储 65,535 字节。
- **BLOB**: 二进制大对象，存储大量二进制数据。

4. **枚举和集合类型**

- **ENUM**: 枚举类型，允许从预定义的值中选择一个。
- **SET**: 集合类型，允许从预定义的值中选择多个。

常用的约束：`PRIMARY KEY`（主键）、`UNIQUE`（唯一）、`NOT NULL`（非空）、`DEFAULT`（默认值）、`AUTO_INCREMENT`（自动增长）、`FOREIGN KEY`（外键）

```sql
PRIMARY KEY (column_name)
UNIQUE (column_name)
column_name datatype NOT NULL
column_name datatype DEFAULT default_value
column_name INT NOT NULL AUTO_INCREMENT
FOREIGN KEY (column_name) REFERENCES other_table(other_column)
```

**CRUD**

```sql
INSERT INTO table_name (column1, column2, column3, ...)
VALUES (value1, value2, value3, ...);

INSERT INTO table_name (column1, column2, column3, ...)
VALUES
    (value1_1, value1_2, value1_3, ...),
    (value2_1, value2_2, value2_3, ...),
    (value3_1, value3_2, value3_3, ...);

DELETE FROM table_name
WHERE condition;

SELECT column1, column2, ...
FROM table_name
WHERE condition;

UPDATE table_name
SET column1 = value1, column2 = value2, ...
WHERE condition;
```

**设置索引的方法**

1. **创建表时设置索引**： 在创建表的同时，可以指定索引。例如，创建一个包含索引的表：

   ```sql
   CREATE TABLE users (
       id INT PRIMARY KEY,
       username VARCHAR(50),
       email VARCHAR(100),
       INDEX (username)
   );
   ```

2. **使用`CREATE INDEX`语句创建索引**： 在表创建后，可以使用`CREATE INDEX`语句添加索引。例如：

   ```sql
   CREATE INDEX index_name
   ON table_name (column_name);
   ```

3. **使用`ALTER TABLE`语句创建索引**： 通过`ALTER TABLE`语句，可以为现有表添加索引。例如：

   ```sql
   ALTER TABLE table_name
   ADD INDEX index_name (column_name);
   ```

## NOSQL和SQL的区别？

关系型数据库（RDBMS）和非关系型数据库（NoSQL）主要在数据存储结构、查询方式、扩展性以及适用场景上存在区别。

1）数据存储结构：RDBMS使用表格来存储数据，其数据结构主要包括表（tables）、行（rows）、列（columns），每个表都有预定义的架构。NoSQL数据库则采用更加灵活的存储方式，包括键值对存储（Key-Value）、列族存储（Column-Family）、文档存储（Document Store）和图存储（Graph Store）等。

2）查询方式：RDBMS往往使用结构化查询语言（SQL）来进行数据查询和操作，支持复杂的查询和事务处理。NoSQL数据库大多采用自身特定的查询语言或者API来进行数据操作，某些NoSQL数据库在支持复杂查询方面不如RDBMS。

3）扩展性：RDBMS通常通过垂直扩展（增加单个服务器的硬件资源）来提升性能，而NoSQL数据库多采用水平扩展（添加更多节点）来实现扩展性，适合处理大规模数据和高并发场景。

4）适用场景：RDBMS适用于数据关系明确、结构化程度高的应用场景，如金融、政府系统等。NoSQL则适用于处理海量的、分布广泛、不确定结构的数据，如社交媒体、内容管理等系统。

## 数据库三大范式是什么？

第一范式（1NF）：确保表中的每个列都是原子的，也就是说，每个列的值不能再分解成更小的值。1NF要求表中的每个字段只能包含单一值，而不能是列表或数组。 如家庭信息是：3口人、北京

第二范式（2NF）：在满足1NF的基础上，要求表中的每个非主属性（非键属性）都完全依赖于主键，而不是仅依赖于主键的一部分。

第三范式（3NF）：在2NF基础上，任何非主属性 (opens new window)不依赖于其它非主属性（在2NF基础上消除传递依赖） 第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。

## MySQL如何避免重复插入数据？

方式一：使用UNIQUE约束 在表的相关列上添加UNIQUE约束，确保每个值在该列中唯一。例如： 

```sql
CREATE TABLE users ( 
    id INT PRIMARY KEY AUTO_INCREMENT, 
    email VARCHAR(255) UNIQUE, 
    name VARCHAR(255) 
);
```

 如果尝试插入重复的email，MySQL会返回错误。

方式二：使用INSERT ... ON DUPLICATE KEY UPDATE 这种语句允许在插入记录时处理重复键的情况。如果插入的记录与现有记录冲突，可以选择更新现有记录：

```sql
 INSERT INTO users (email, name) 
 VALUES ('example@example.com', 'John Doe') 
 ON DUPLICATE KEY UPDATE name = VALUES(name); 
```

方式三：使用INSERT IGNORE： 该语句会在插入记录时忽略那些因重复键而导致的插入错误。例如： 

```sql
INSERT IGNORE INTO users (email, name) 
VALUES ('example@example.com', 'John Doe');
```

 如果email已经存在，这条插入语句将被忽略而不会返回错误。 

选择哪种方法取决于具体的需求： 

如果需要保证全局唯一性，使用UNIQUE约束是最佳做法。 

如果需要插入和更新结合可以使用ON DUPLICATE KEY UPDATE。

 对于快速忽略重复插入，INSERT IGNORE是合适的选择

## CHAR 和 VARCHAR有什么区别？

- CHAR是固定长度的字符串类型，定义时需要指定固定长度，存储时会在末尾补足空格。CHAR适合存储长度固定的数据，如固定长度的代码、状态等，存储空间固定，对于短字符串效率较高。 
- VARCHAR是可变长度的字符串类型，**定义时需要指定最大长度**，实际存储时根据实际长度占用存储空间。VARCHAR适合存储长度可变的数据，如用户输入的文本、备注等，节约存储空间。

## Text数据类型可以无限大吗？

MySQL 3 种text类型的最大长度如下： 

TEXT：65,535 bytes ~64kb 

MEDIUMTEXT：16,777,215 bytes ~16Mb LONGTEXT：

4,294,967,295 bytes ~4Gb

## 说一下外键约束

外键约束的作用是维护表与表之间的关系，确保数据的完整性和一致性。让我们举一个简单的例子： 假设你有两个表，一个是学生表，另一个是课程表，这两个表之间有一个关系，即一个学生可以选修多门课程，而一门课程也可以被多个学生选修。在这种情况下，我们可以在学生表中定义一个指向课程表的外键，如下所示： 

```sql
CREATE TABLE students ( 
	id INT PRIMARY KEY, 
	name VARCHAR(50), 
	course_id INT, 
	FOREIGN KEY (course_id) REFERENCES courses(id) 
); 
```

这里，students表中的course_id字段是一个外键，它指向courses表中的id字段。这个外键约束确保了每个学生所选的课程在courses表中都存在，从而维护了数据的完整性和一致性。 

如果没有定义外键约束，那么就有可能出现**学生选了不存在的课程或者删除了一个课程而忘记从学生表中删除选修该课程的学生的情况**，这会破坏数据的完整性和一致性。因此，使用外键约束可以帮助我们避免这些问题。

## MySQL的关键字in和exist 

在MySQL中，IN 和 EXISTS 都是用来处理子查询的关键词，但它们在功能、性能和使用场景上有各自的特点和区别。 **IN关键字** 

IN 用于检查左边的表达式是否存在于右边的列表或子查询的结果集中。如果存在，则IN 返回TRUE，否则返回FALSE。

**EXISTS关键字**

EXISTS 用于判断子查询是否至少能返回一行数据。它不关心子查询返回什么数据，只关心是否有结果。如果子查询有结果，则EXISTS 返回TRUE，否则返回FALSE。



区别与选择： 

性能差异：在很多情况下，EXISTS 的性能优于 IN，特别是当子查询的表很大时。这是因为EXISTS 一旦找到匹配项就会立即停止查询，而IN可能会扫描整个子查询结果集。

使用场景：如果子查询结果集较小且不频繁变动，IN 可能更直观易懂。而当子查询涉及外部查询的每一行判断，并且子查询的效率较高时，EXISTS 更为合适。 

NULL值处理：IN 能够正确处理子查询中包含NULL值的情况，而EXISTS 不受子查询结果中NULL值的影响，因为它关注的是行的存在性，而不是具体值。

## Mysql底层索引结构是什么？为什么这个更好？

### B+ 树索引

B+ 树是一种平衡树，所有的值都存储在叶子节点中，并且叶子节点通过指针顺序连接，便于范围查询。B+ 树索引是 MySQL 中最常用的索引类型，尤其是在 InnoDB 存储引擎中。

#### B+ 树结构

- **根节点**：树的最高层，包含指向子节点的指针。
- **内部节点**：中间层节点，包含键值和指向子节点的指针。
- **叶子节点**：存储实际的键值和数据记录指针，所有叶子节点通过指针顺序连接。

#### 优点

1. **平衡性**：B+ 树是平衡树，插入和删除操作会自动保持树的平衡，确保所有叶子节点在同一层，查询效率稳定。
2. **顺序访问**：叶子节点通过指针顺序连接，方便范围查询和排序操作。
3. **磁盘读写优化**：B+ 树节点大小通常与磁盘页大小一致，减少了磁盘 I/O 次数，提升了查询性能。
4. **高效的插入和删除**：由于树的平衡性，插入和删除操作的平均时间复杂度为 O(log N)。

首先，它是一种多叉树结构，这意味着每个节点可以有多个孩子节点，不像二叉树那样每个节点只能有两个孩子。这样的设计使得树的高度降低，进而提高了检索效率，因为我们在查找数据时需要的比较次数减少了。

其次，B+树的内部节点，也就是非叶子节点，是不存储数据的，它们只存储键值和指向子节点的指针。而所有的数据都存储在叶子节点上。这样的设计让内部节点可以容纳更多的键值，进一步降低了树的高度。

再者，B+树的叶子节点之间是通过指针相连的，形成了一个有序链表。这种结构特点让范围查询变得非常简单和高效，因为我们可以直接通过叶子节点的指针进行顺序访问。

最后，B+树还具有良好的平衡性。在插入或删除数据时，B+树会通过分裂或合并节点来保持平衡，从而确保查询性能的稳定。

## MySQL的乐观锁和悲观锁是什么？

### 乐观锁

乐观锁的核心思想是认为在大多数情况下数据并不会发生冲突，因此在数据更新时不主动加锁，而是在提交数据更新时检查是否存在冲突。它常用于在高并发环境下减少锁的开销。

**实现方式：**

- **版本号机制**：最常见的乐观锁实现方式是在数据表中增加一个版本号字段（`version`），每次更新数据时同时更新版本号。

**例子：**
 假设我们有一张用户表`user`，包括字段`id`、`name`和`version`：

```
SELECT version FROM user WHERE id = 1; -- 读取数据及版本号
-- 更新操作时检查版本号是否匹配
UPDATE user SET name = 'new_name', version = version + 1 
WHERE id = 1 AND version = old_version;
```

在更新数据时，只有`version`字段与之前读取的一致，更新操作才会成功，否则说明数据在此期间被其他事务修改过，更新失败，需要重新读取和处理。

**适用场景：**

- 适合于大量读操作而较少写操作的场景，这样可以提升系统的并发性能。
- 高并发环境下避免频繁加锁带来的性能开销。

### 悲观锁

> 悲观锁的核心思想是认为对数据的冲突会频繁发生，因此在对数据进行操作之前主动加锁，避免其他事务访问该数据。悲观锁在操作过程中会保持锁定状态，直到事务提交或回滚。
>
> **实现方式：**
>
> - **数据库中的行级锁**：常见的实现方法是使用SQL语句加锁，如`SELECT ... FOR UPDATE`。
>
> **例子：**
>  假设我们有一张用户表`user`，包括字段`id`和`name`：
>
> ```
> BEGIN;
> SELECT * FROM user WHERE id = 1 FOR UPDATE; -- 读并锁定数据行
> -- 更新操作
> UPDATE user SET name = 'new_name' WHERE id = 1;
> COMMIT;
> ```
>
> 在执行`SELECT ... FOR UPDATE`语句时，会对返回的行加锁，其他事务在该行被锁定期间无法更新数据。
>
> **适用场景：**
>
> - 适合于写操作频繁且数据竞争激烈的场景，可以有效防止并发写操作的冲突。
> - 需要确保数据的强一致性，不允许丢失任何更新时。

## 为什么索引可以提高效率

### 索引提高效率的原因

1. **减少数据扫描量**： 没有索引时，数据库在查询数据时需要扫描整个表，而有了索引后，数据库可以直接通过索引定位到特定的记录，从而大大减少需要扫描的数据量。
2. **快速查找**： 索引通常采用B树或哈希表等数据结构，能够在对数时间复杂度内找到目标数据。这使得查找操作非常高效。
3. **排序优化**： 有些索引，如B树索引，是按顺序存储的。因此，当查询中包含`ORDER BY`子句时，可以直接利用索引进行排序，无需额外的排序开销。
4. **优化聚合操作**： 对于包含`GROUP BY`和`COUNT`等聚合操作的查询，索引可以帮助更快地分组和统计数据，提高查询效率。

## MYSQL存储引擎的对比

### InnoDB

**事务支持**：InnoDB是事务型数据库的首选引擎，它提供了**提交、回滚和崩溃恢复能力**来保护用户数据，确保数据的完整性。它遵循ACID原则，即原子性、一致性、隔离性和持久性。

**行级锁定**：InnoDB支持行级锁定，这意味着在多个用户并发访问数据库时，它只会锁定被访问的行，而不是整个表。这大大提高了数据库的并发性能。

**外键约束**：InnoDB还支持外键约束，可以确保数据的参照完整性。

**聚簇索引**：InnoDB使用聚簇索引，即**数据和主键索引**存储在一起，这有助于提高某些查询的效率。

### **MyISAM存储引擎：**

**表级锁定**：MyISAM不支持事务和行级锁定，只支持表级锁。这意味着在读写操作时，会对整个表进行锁定，可能导致并发性能较差。

**全文索引**：MyISAM支持全文索引，适合进行文本搜索。

**高速读取**：MyIAM通常用于只读或大量读取的应用场景，其查询速度相对较快。

**压缩存储**：MyISAM还支持压缩表，可以节省存储空间。

### 其他存储引擎：

**Memory**：将所有数据保存在RAM中，提供极快的访问速度，适用于需要快速查找引用的场景。但服务器关闭时数据会丢失。

总的来说，选择哪种存储引擎取决于具体的应用需求和性能要求。例如，对于需要高并发写入和数据完整性的应用，InnoDB是更好的选择；而对于只读或文本搜索为主的应用，MyISAM可能更合适。在实际应用中，我们需要根据具体情况进行权衡和选择。

## 一条SQL的执行流程

连接器->查询缓存->解析SQL->执行SQL 	

**第一阶段：连接器**

当用户尝试连接到MySQL数据库时，首先会经过连接器。连接器的主要任务是**验证客户端的身份**，例如检查用户名和密码是否正确。如果验证通过，连接器还会到权限表中查询该用户所拥有的权限。连接成功后，用户的会话信息会被缓存起来，这样在后续的连接请求中，如果连接参数相同，就可以重用之前的会话信息，避免重复进行身份验证。

**第二阶段：缓存**

在MySQL中，为了提高查询效率，有一个**查询缓存**的机制。当接收到一个查询请求时，MySQL会先检查查询缓存，看看是否之前已经执行过相同的查询。如果是，那么MySQL会直接从缓存中获取结果并返回给客户端，从而跳过后续的解析和执行阶段。但需要注意的是，查询缓存的维护也是有一定开销的，特别是在数据变更频繁的场景下，查询缓存可能会导致性能下降，因为每次数据变更都会导致相关的查询缓存失效。

**第三阶段：解析SQL**

如果查询缓存中没有找到匹配的结果，MySQL就需要对SQL语句进行解析。解析器会先对SQL语句进行词法和语法分析，将其转换成一个“解析树”。这个过程中会检查SQL语句的语法是否正确，如果不正确，就会返回错误信息给客户端。

**第四阶段：预处理与优化**

解析完SQL语句后，MySQL会对其进行预处理和优化。预处理主要是检查解析树中的==表和列是否存在==，数据类型是否正确等。优化器则负责根据解析树生成一个==高效的执行计划==。优化器会考虑多种可能的执行路径，并选择其中成本最低的一种。这个成本是基于对数据的统计信息来计算的，比如表的大小、索引的分布情况等。

**第五阶段：执行SQL**

根据优化器生成的执行计划，MySQL开始执行SQL语句。如果是查询操作，MySQL会按照执行计划中的步骤逐步检索数据，并最终返回给客户端。如果是更新操作（如INSERT、UPDATE或DELETE），MySQL会先对数据进行修改，并可能触发相关的约束和触发器。在这个过程中，MySQL还需要维护数据的完整性和一致性。

**第六阶段：返回结果**

最后，MySQL会将执行结果返回给客户端。对于查询操作，这通常是一个结果集，包含了满足条件的记录；对于更新操作，可能是一个表示操作成功或失败的状态码。

以上就是MySQL中一条SQL语句的执行过程。

## mysql主键怎么选择

### 1. **自然主键 vs. 人工主键**

- **自然主键**：使用表中已经存在且具有唯一性的列作为主键，比如社会保障号码、电子邮件地址、或身份证号码。这种主键来源于实际业务逻辑。
- **人工主键**：通常是数据库系统自动生成的值，例如自增的整数或UUID。这种主键与业务无关，仅用于数据库内部。

**建议**：

- 优先选择人工主键，因为它们通常更简单、更稳定。自然主键可能会因为业务变化导致数据更新，甚至出现重复值的情况，导致数据库维护复杂化。

### 2. **自增整数主键**

- **特点**：整数类型（如 `INT`, `BIGINT`）通常用作主键，因为它们占用的空间小，且性能较高。自增整数主键（`AUTO_INCREMENT`）是最常用的人工主键，数据库会为每一行自动分配唯一的连续数字。
- 优点
  - 简单易用。
  - 性能高，因为数据库可以很容易地进行索引和排序操作。
  - 生成的主键值是连续的，这对B+树索引友好，有助于减少页分裂。

**建议**：

- 在大多数情况下，使用自增整数主键是最简单且高效的选择，尤其是在不需要全球唯一的情况下。

### 3. **UUID主键**

- **特点**：UUID（通用唯一标识符）是一种128位的标识符，通常用作分布式系统中的主键。它们是全球唯一的，但相对于整数，UUID占用的空间大且排序性能较差。
- 优点
  - 全球唯一性，适用于分布式数据库或需要跨多个数据库实例的唯一标识符。
  - 不易被猜测或推测出模式，增加了一定的安全性。
- 缺点
  - 占用空间较大（16字节），会增加存储和索引开销。
  - 在排序和索引操作时性能较差，特别是在B+树索引结构中，UUID是随机分布的，容易导致页分裂。

**建议**：

- 仅在需要全球唯一标识符或在分布式系统中需要无冲突主键时使用UUID。在其他情况下，尽量避免使用UUID作为主键。

### 4. **复合主键**

- **特点**：复合主键由表中的多列组成，组合起来保证行的唯一性。例如，使用 `user_id` 和 `order_id` 作为订单表的复合主键。
- 优点
  - 在某些情况下，使用复合主键可以减少表中的冗余数据。
- 缺点
  - 索引较复杂，涉及多列的联合索引，可能导致性能下降。
  - 复合主键的大小往往较大，影响查询和存储性能。

**建议**：

- 尽量避免使用复合主键，除非在特定情况下确实需要。如果必须使用复合主键，确保各个字段的组合是稳定且不会频繁变化的。

### 5. **选择主键的其他考虑因素**

- **唯一性**：主键必须保证唯一性，无论选择哪种类型的主键，都要确保它在表中不会重复。
- **不可变性**：主键一旦分配给一行数据，通常不应改变。选择主键时应避免选择那些可能需要更新的列。
- **性能**：主键会被自动索引，因此选择主键时要考虑它对数据库性能的影响。整数类型的主键一般比字符串或UUID类型的主键更高效。

## 索引的分类

### 数据结构

**B+tree索引**：

这是最常用的索引类型，特别是在InnoDB和MyISAM存储引擎中。

B+tree索引能够处理全键值、键值范围和前缀查询。

在InnoDB中，它使用的是B+tree结构，这是一种平衡的树结构，能够保持数据的有序性，从而加速查询性能。

**Hash索引**：

主要在MEMORY存储引擎中使用，但也可以在其他引擎中通过特定方式实现。

Hash索引基于哈希表实现，适用于等值查询，但不适合范围查询和排序操作。

它的查找速度非常快，但缺点是数据不是按照索引值顺序存储的。

**Full-text索引**：

主要用于文本搜索，支持在MyISAM和InnoDB存储引擎上创建。

它允许你在文本字段上进行高效的全文搜索。

## 物理存储

**聚簇索引（主键索引）**：在InnoDB中，表数据实际上是按照主键的顺序存储的，这种索引称为聚簇索引。因此，主键查询在InnoDB中是非常高效的。

**二级索引（辅助索引）** ：除了主键索引外，其他所有的索引都可以看作是二级索引。在InnoDB中，二级索引的叶子节点存储的是主键值，而不是实际的数据记录。

## 字段特性

**主键索引**：基于表的主键字段创建的索引，具有唯一性。

**普通索引**：建立在普通字段上的索引，允许在索引的列中插入重复值和空值。

**唯一索引**：建立在UNIQUE上的索引，确保索引列的组合值是唯一的，类似于主键索引，但允许有空值。

**前缀索引**：前缀索引是指对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，前缀索引可以建立在字段类型为 char、 varchar、binary、varbinary 的列上。

## 字段个数

**单列索引**：仅包含表中的一个列。

**联合索引（复合索引、组合索引）** ：包含表中的多个列，可以提高多个列的查询效率。

需要注意的是，不同的存储引擎支持的索引类型和特性可能会有所不同。例如，MEMORY存储引擎默认使用Hash索引，而InnoDB和MyISAM则主要使用B+tree索引。在选择索引类型和存储引擎时，需要根据具体的应用需求和性能要求来进行权衡。

## B+树索引结构介绍？为什么使用B+树而不是B树？

### B+树结构介绍

首先，它是一种多叉树结构，这意味着每个节点可以有多个孩子节点，不像二叉树那样每个节点只能有两个孩子。这样的设计使得树的高度降低，进而提高了检索效率，因为我们在查找数据时需要的比较次数减少了。【**多叉树**】

其次，B+树的内部节点，也就是非叶子节点，是不存储数据的，它们只存储键值和指向子节点的指针。而所有的数据都存储在叶子节点上。这样的设计让内部节点可以容纳更多的键值，进一步降低了树的高度。【**只有子节点存储数据，容纳更多键值**】

再者，B+树的叶子节点之间是通过指针相连的，形成了一个有序链表。这种结构特点让范围查询变得非常简单和高效，因为我们可以直接通过叶子节点的指针进行顺序访问。【**链表，顺序访问**】

最后，B+树还具有良好的平衡性。在插入或删除数据时，B+树会通过分裂或合并节点来保持平衡，从而确保查询性能的稳定。【**平衡性**】

### 为什么用B+树而不是B树？

一、树的高度

B+树相较于B树，其树的高度更低。这是因为B+树的非叶子节点不存储数据，只存储索引，因此可以容纳更多的子节点，使得整个树的结构更加扁平化。这种设计减少了查询时需要经过的层级数，最重要是减少了磁盘IO的次数，从而提高了查询效率。相比之下，B树的每个节点都存储数据，导致节点容纳的子节点数量有限，树的高度相对较高。

二、插入删除效率

在插入和删除操作方面，B+树也表现出更高的效率。由于B+树的非叶子节点不存储数据，因此在插入或删除数据时，==只需要调整索引结构==，而不需要频繁地移动大量数据。这大大简化了插入和删除操作的过程，并提高了效率。相比之下，B树在插入或删除数据时可能需要更复杂的操作来保持树的平衡。

三、范围查询效率

B+树在范围查询方面具有显著优势。由于B+树的叶子节点包含所有数据，并且叶子节点之间通过指针相连，形成了一个有序链表结构。这种结构使得范围查询变得非常简单和高效，因为我们可以直接通过叶子节点的指针顺序访问范围内的数据。而在B树中，范围查询可能需要更复杂的中序遍历操作。 12月1 到12 月12，B+链表顺序，而B树每次只能中序遍历

## 二级索引？查找过程？覆盖索引？索引下推？

### 存储内容

在数据库，二级索引通常存储在单独的数据结构中，如B+树。与聚簇索引不同，二级索引的叶子节点并不包含整行数据，而是存储了索引列的值和对应的主键值。这意味着，当我们通过二级索引查找数据时，我们首先找到的是与查询条件匹配的主键值，而不是直接找到完整的记录。

### 查找过程

**定位索引列的值**：在二级索引中，根据查询条件中的索引列值，数据库可以快速定位到匹配的索引记录。这个过程是通过在B+树中进行搜索实现的，时间复杂度相对较低。

**获取主键值**：一旦找到匹配的索引记录，我们可以从中获取到对应的主键值。这个主键值是连接二级索引和聚簇索引的桥梁。

**回表操作**：有了主键值后，我们需要回到聚簇索引中进行查找，这个过程被称为“回表”。在聚簇索引中，主键值直接与数据记录相关联，因此我们可以通过主键值直接找到完整的数据记录。

### 覆盖索引

如果查询的列都包含在二级索引中，那么我们就可以直接使用二级索引进行查询，而无需进行回表操作。这种情况被称为“覆盖索引”。覆盖索引可以显著提高查询效率，因为它减少了磁盘I/O操作和数据查找的复杂性。

### 索引下推

在某些情况下，数据库可以使用一种称为“索引下推”的优化技术来进一步提高查询效率。索引下推允许数据库在二级索引层面就进行部分过滤操作，从而减少需要回表的数据量。这种优化可以在某些复杂的查询条件下显著提高性能。

## 最左匹配原则？

一、什么是最左匹配原则

最左匹配原则是MySQL中联合索引查询时遵循的一个重要原则。它指的是在使用联合索引进行查询时，查询条件中必须包含索引的最左边（即第一个）字段，才能有效地利用索引进行查询优化，**字段在 where 子句的顺序并不重要**。如果查询条件没有包含最左边的字段，那么索引将不会被使用，这可能会导致查询性能下降。

二、最左匹配原则的原理

最左匹配原则的原理基于B+树索引的结构特点。在MySQL中，索引是以B+树的形式存在的，联合索引也不例外。B+树索引是按照从左到右的顺序进行构建的，因此，在查询时也需要按照相同的顺序进行匹配。

当查询条件中包含了联合索引的最左字段时，数据库可以快速地定位到符合条件的记录所在的位置，从而提高查询效率。如果查询条件没有包含最左字段，那么数据库就需要进行全表扫描，这会大大降低查询性能。

## 什么时候需要/不需要索引

索引最大的好处是提高查询速度，但是索引也是有缺点的，比如：

- 需要占用**物理空间**，数量越大，占用空间越大；
- **创建索引和维护索引要耗费时间**，这种时间随着数据量的增加而增大；
- 会降低表的增删改的效率，因为每次增删改索引，B+ 树为了维护索引有序性，都需要进行动态维护。

所以，索引不是万能钥匙，它也是根据场景来使用的。

#### 什么时候适用索引？

- 字段有**唯一性限制**的，比如商品编码；
- 经常用于 `WHERE` 查询条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。
- 经常用于 `GROUP BY` 和 `ORDER BY` 的字段，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的。

#### 什么时候不需要创建索引？

- `WHERE` 条件，`GROUP BY`，`ORDER BY` 里用不到的字段，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的。
- 字段中存在大量重复数据，不需要创建索引，比如性别字段，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。
- 表数据太少的时候，不需要创建索引；
- 经常更新的字段不用创建索引，比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能的。

## 索引失效的场景

**联合索引非最左匹配**：当我们使用联合索引时，必须遵循最左匹配原则。也就是说，查询条件中必须使用索引的最左边的一列，否则索引将不会起作用。例如，如果我们有一个基于列A和列B的联合索引，但查询条件只涉及列B，那么该索引将不会被使用。

**不恰当的模糊查询**：在使用LIKE进行模糊查询时，如果查询模式以通配符开头（例如，LIKE '%xyz'），那么索引将不会起作用。因为数据库无法有效利用索引来加速这种模式的搜索。只有当模糊查询的模式是以确定字符开头时（例如，LIKE 'xyz%'），索引才能被有效利用。

**对索引列进行计算或函数操作**：如果在查询中对索引列进行了计算或应用了函数，那么索引将失效。例如，如果我们对一个索引列进行了加法或乘法运算，或者使用了某种函数如UPPER()或LOWER()来处理索引列的值，那么数据库将无法使用索引来加速查询。

**隐式类型转换**：当在查询过程中发生隐式数据类型转换时（例如，将字符串与数字进行比较），这可能会导致索引失效。因为转换后的值可能无法与索引中的值直接匹配。

**使用OR操作符**：当查询条件中包含多个使用OR连接的子条件时，如果子条件涉及的列不是全部被索引覆盖，那么索引可能会失效。因为数据库可能无法有效地利用单个索引来满足所有OR条件。

**使用IS NOT NULL或!=操作符**：在某些数据库中，使用IS NOT NULL或!=操作符进行查询时，可能会导致索引失效。因为这些操作符需要扫描整个表来找到不匹配的行。

## 事务的ACID说一下？四种特性如何得到保证的的？

### ACID介绍

事务的ACID特性是数据库管理系统在处理事务时所必须遵循的四个基本原则，它们分别是原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）。下面我将逐一介绍这四个特性及其在实现层面是如何得到保证的。

首先是**原子性**。原子性意味着事务是一个不可分割的工作单位，事务中的操作要么全部完成，要么全部不完成。实现原子性的关键在于事务管理机制，它确保了一组相关的数据库操作要么全部执行成功，要么在发生错误时全部回滚到事务开始前的状态。这主要通过数据库管理系统的日志机制和回滚技术来实现。在事务执行过程中，系统会记录所有的操作日志，一旦发生错误，系统可以利用这些日志来回滚到事务开始前的状态，从而保证原子性。（**原子性是通过 undolog 来保证的**）

接下来是**一致性**。一致性要求事务执行前后，数据库的状态必须保持一致。这意味着，如果事务在执行过程中因为某些原因而中断，数据库系统必须能够恢复到事务开始前的状态，以保持数据的一致性。数据库管理系统通过一系列完整性约束、触发器和级联更新等操作来维护数据的一致性。同时，在事务结束时，系统会对数据库的状态进行检查，以确保所有的约束条件都得到满足，如果有不一致的情况，事务会被回滚。）

再来说说**隔离性**。隔离性是指多个并发事务之间不会互相影响。为了实现隔离性，数据库管理系统采用了锁机制来控制对数据的并发访问。通过锁定正在被访问的数据，可以确保在事务完成之前，其他事务无法修改这些数据。此外，数据库还提供了不同的隔离级别，如读未提交、读已提交、可重复读和串行化等，以满足不同应用场景下的隔离需求。（**隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的**）

最后是**持久性**。持久性意味着一旦事务提交，其对数据库中数据的修改将是永久性的。为了实现持久性，数据库管理系统采用了写前日志（Write-Ahead Logging）技术。在事务提交前，系统会先将事务的修改记录在日志中，并确保这些日志已经持久化到磁盘上。这样，即使数据库系统发生故障或重启，已经提交的事务的修改也不会丢失，因为系统可以根据日志来恢复数据到一致的状态。（**持久性是通过 redo log （重做日志）来保证的**）

### ACID四种特性如何得到保证的的？

- 持久性是通过 redo log （重做日志）来保证的；
- 原子性是通过 undo log（回滚日志） 来保证的；
- 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；
- 一致性则是通过持久性+原子性+隔离性来保证；

## 脏读，不可重复读，幻读？

### 脏读

**如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。**

### 不可重复读

**在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。**

### 幻读

**在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。**

## 事务隔离级别？

**读未提交（Read Uncommitted）** ：

- 这是最低的隔离级别。在此级别下，一个事务可以读取另一个事务尚未提交的数据。
- 这种级别的问题在于，它可能导致“脏读”（Dirty Read）问题，即读取到未经确认的临时数据。
- 由于这个原因，这个隔离级别在实际应用中很少使用。

**读已提交（Read Committed）** ：

- 在这个级别，每个查询都会在事务执行时获取当前可见的数据。
- 它可以避免脏读，因为只能读取已提交的数据。
- 但这种级别可能导致“不可重复读”（Non-repeatable Read）问题，即同一个查询在多次执行时可能读取到不同的数据，因为其他事务可能在此期间修改了数据。

**可重复读（Repeatable Read）** ：

- 这是MySQL InnoDB引擎的默认事务隔离级别。
- 在这个级别下，事务在开始时“快照”当前状态，因此它看到的是一致的数据视图，在事务执行期间不会改变。
- 这可以避免脏读和不可重复读问题。
- 但这种级别可能导致“幻读”（Phantom Read）问题，即当事务读取某个范围内的记录时，另一个并发事务插入了一些新的记录，导致前一个事务在再次读取该范围的记录时，会看到一些“幻影”记录。
- InnoDB通过多版本并发控制（MVCC）和next-key lock来解决这个问题。

**串行化（Serializable）** ：

- 这是最高的隔离级别。
- 在这个级别下，事务是完全串行执行的，避免了脏读、不可重复读和幻读问题。
- 它通过在事务执行期间对数据加锁来实现，这可以防止其他事务对数据进行修改和插入。
- 但这种严格的控制可能会导致大量的锁竞争和性能开销。

## MVCC的工作原理

MVCC的工作原理是基于数据版本的管理。每当数据被修改时，数据库不是直接更新原始数据，而是创建一个新的数据版本。每个版本都与一个事务ID相关联，这个ID表示哪个事务创建了该版本。当事务进行读取操作时，数据库会根据该事务的隔离级别和当前活跃的事务列表来决定哪个版本的数据应该被返回。

此外，MVCC还依赖于一种称为“Read View”的机制来确定哪些版本的数据对当前事务是“可见”的。Read View本质上是一个事务ID的列表，它表示在当前事务开始时尚未提交的其他事务。通过这个列表，数据库可以判断哪些数据版本对当前事务是不可见的（因为它们是由尚未提交的事务创建的）。

## Read View 在 MVCC 里如何工作的？

### Read View 有四个重要的字段：

- m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的**事务 id 列表**，注意是一个列表，**“活跃事务”指的就是，启动了但还没提交的事务**。
- min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 **id 最小的事务**，也就是 m_ids 的最小值。
- max_trx_id ：这个并不是 m_ids 的最大值，而是**创建 Read View 时当前数据库中应该给下一个事务的 id 值**，也就是全局事务中最大的事务 id 值 + 1；
- creator_trx_id ：指的是**创建该 Read View 的事务的事务 id**。

### 聚簇索引记录中的两个隐藏列

对于使用 InnoDB 存储引擎的数据库表，它的聚簇索引记录中都包含下面两个隐藏列：

- trx_id，当一个事务对某条聚簇索引记录进行改动时，就会**把该事务的事务 id 记录在 trx_id 隐藏列里**；
- roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后**这个隐藏列是个指针，指向每一个旧版本记录**，于是就可以通过它找到修改前的记录。

一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：

- 如果记录的 trx_id 值小于 Read View 中的 `min_trx_id` 值，表示这个版本的记录是在创建 Read View **前**已经提交的事务生成的，所以该版本的记录对当前事务**可见**。
- 如果记录的 trx_id 值大于等于 Read View 中的 `max_trx_id` 值，表示这个版本的记录是在创建 Read View **后**才启动的事务生成的，所以该版本的记录对当前事务**不可见**。
- 如果记录的 trx_id 值在 Read View 的`min_trx_id`和`max_trx_id`之间，需要判断 trx_id 是否在 m_ids 列表中：
  - 如果记录的 trx_id **在** `m_ids` 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务**不可见**。
  - 如果记录的 trx_id **不在** `m_ids`列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务**可见**。

**这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。**

### 读已提交

**读提交隔离级别是在每次读取数据时，都会生成一个新的 Read View**。

### 可重复读

**可重复读隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View**。

## 可重复读在什么情况下还存在幻读

混用

第一个例子：对于快照读， MVCC 并不能完全避免幻读现象。因为当事务 A 更新了一条事务 B 插入的记录，那么事务 A 前后两次查询的记录条目就不一样了，所以就发生幻读。

第二个例子（先快照读后当前读）：对于当前读，如果事务开启后，并没有执行当前读（没有加上for update），而是先快照读，然后这期间如果其他事务插入了一条记录，那么事务后续使用当前读进行查询的时候，就会发现两次查询的记录条目就不一样了，所以就发生幻读。

## 慢SQL排查？优化？

**慢SQL排查**

**监控数据库性能**：首先，我会密切关注数据库的性能指标，如CPU利用率、内存利用率和磁盘I/O等。比如，如果CPU或内存使用率过高，可能就意味着有慢SQL存在。这些指标能帮助我初步定位可能存在问题的地方。

**查看慢查询日志**：数据库通常会记录执行时间较长的查询，即慢查询日志。通过查看这些日志，我可以找到那些执行时间较长的SQL语句，这是定位慢SQL的直接方法。

**使用执行计划工具分析**：对于疑似慢SQL的语句，我会使用数据库的执行计划工具进行分析。执行计划能展示SQL语句的执行步骤和涉及的表、索引等信息，从而帮助我找到性能瓶颈。

**二、慢SQL优化**

**检查并优化索引**：索引是提高查询性能的关键。我会检查现有的索引是否合理，是否能够支持SQL语句的快速执行。如果发现索引缺失或不合理，我会考虑添加、修改或删除索引。

**改写SQL语句**：有时候，慢SQL的产生是因为SQL语句本身存在问题，如查询条件不合理或表连接方式不正确。在这种情况下，我会尝试改写SQL语句，比如优化查询条件，合理使用索引，或者重构查询语句以提高性能。

**调整数据库参数**：数据库的性能也与其参数的设置有关。我会根据实际情况调整数据库的参数，如MySQL的`innodb_buffer_pool_size`和`max_connections`等，以提高性能。（比如buffer pool太小，会在写入脏页时引入性能开销，导致慢sql）

**考虑分库分表**：如果数据库中的数据量过大，也可能导致SQL执行时间较长。在这种情况下，我会考虑对数据库进行分库分表，以分散数据存储和查询的压力。

## 介绍下分库分表？

### 为什么要要进行分库分表？

**解决数据库连接资源不足问题**（max_connection 151）

在高并发的场景下，大量请求同时访问数据库，可能会导致数据库连接资源紧张。通过分库，可以将连接分散到多个数据库上，从而有效地减轻单个数据库的连接压力。此外，单个数据库也是有连接数量限制的，max_connection默认151个。

**缓解磁盘IO的性能瓶颈**

当单库数据量过大时，磁盘IO可能成为性能瓶颈。分库可以将数据分散到不同的物理存储上，降低单个数据库的磁盘IO负载，提高整体性能。

**解决单表数据量过大问题**

随着数据的持续增长，单表的数据量可能会达到数百万、数千万甚至更多。这会导致查询效率下降，尤其是当查询条件未命中索引时，全表扫描的耗时将显著增加。分表可以将大表拆分成多个小表，减少单个表的数据量，从而提高查询效率。

**提高并发性能**

分库分表能够将数据和请求分散到多个数据库和表上，从而提高系统的并发处理能力。每个数据库或表只处理部分数据，使得并发请求可以更加均匀地分布，减少了资源争用和锁冲突的可能性。

**提升系统可扩展性**

通过分库分表，可以更容易地扩展系统的数据处理能力。当需要增加更多的数据存储空间或处理能力时，只需简单地添加更多的数据库或表即可。这种水平扩展的方式比垂直扩展（如升级硬件）更加灵活和经济高效。

**增强系统的容错能力**

分库分表还可以提高系统的容错能力。当某个数据库或表出现故障时，其他数据库或表仍然可以继续运行，从而保证了系统的整体稳定性。此外，通过数据冗余和备份策略，可以进一步降低数据丢失的风险。

### 分库分表的方案？

**垂直分库分表**

**垂直分库**：根据业务的耦合性，将一个大的数据库拆分成多个小的数据库，每个数据库服务于不同的业务。这有助于将不同业务的数据进行隔离，提高系统的模块化和可维护性

**垂直分表**：将一个大表中的某些列拆分到另一个表中。这通常用于将不经常使用的数据或大字段（如文本、图片等）拆分出去，以提高查询效率和减少IO压力。

**水平分库分表**

**水平分库**：将数据按照某个字段（如用户ID、订单ID等）的取值范围分配到不同的数据库中。这种方法可以均匀地分散数据压力，提高系统的可扩展性。

**水平分表**：将数据按照某个字段的取值范围分配到同一个数据库的不同表中。这通常用于解决单表数据量过大的问题，通过将数据分散到多个表中，可以提高查询性能和插入/更新的效率。

## Mysql中有哪些锁？

### 全局锁

全局锁是对**整个数据库**实例加锁，通常在执行某些特定的全局操作时需要使用，如备份、数据库迁移等。在MySQL中，可以通过执行FLUSH TABLES WITH READ LOCK语句来获取全局锁。这种锁会阻塞其他会话对数据库的写操作，直到全局锁被释放。需要注意的是，获取全局锁会对数据库的正常运行产生影响，因此应谨慎使用，并在操作完成后及时释放。

### 表级锁

表级锁是锁定整个表，从而阻止其他用户并发访问。在MySQL中，表级锁主要包括以下几种：

**表锁**：最简单的表级锁，直接对整个表进行加锁。这种锁的优点是开销小、加锁快、无死锁，但缺点是锁定粒度大，发生锁冲突的概率最高，并发度最低。

**元数据锁**（MDL）：

- 对一张表进行 CRUD 操作时，加的是 **MDL 读锁**；
- 对一张表做结构变更操作的时候，加的是 **MDL 写锁**；

MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。

当有线程在执行 select 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 select 语句（ 释放 MDL 读锁）。

反之，当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 CRUD 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）。

当对一个表结构进行修改时（例如ALTER TABLE），MySQL会自动为该表加上元数据锁，以防止其他事务在该表上进行DDL或DML操作。这种锁主要用于保证表结构的完整性。

**意向锁**：在InnoDB存储引擎中，当事务准备在某个数据行上加共享锁或排他锁之前，会先在表上获取相应的意向锁。**向锁的目的是为了快速判断表里是否有记录被加锁**。意向锁是兼容的，主要用于在行锁和表锁之间建立一种层级关系。

**AUTO-INC锁**：当插入操作中涉及到自增字段时，MySQL会使用AUTO-INC锁来确保自增值的唯一性。这种锁在插入完成后会立即释放。衍生出一种**轻量级**锁，在完成自增之后就会释放，而不是在等整个插入语句执行完后在释放

### 行级锁

行级锁是锁定表中的某一行或某些行，从而允许其他事务并发访问表中的其他行。在MySQL中，行级锁主要包括以下几种：

记录锁（Record Locks）：直接锁定索引记录，常在更新操作时使用。当某个事务正在对一条记录进行修改时，其他事务无法对该记录进行修改或删除操作。

间隙锁（Gap Locks）：锁定一个范围，但不包括记录本身。这种锁主要用于防止幻读（Phantom Reads），即在一个事务读取某个范围内的记录时，另一个事务插入新的记录到这个范围内。

临键锁（Next-Key Locks）：是记录锁和间隙锁的结合，锁定一个范围并包括记录本身。这种锁可以确保范围内的记录和间隙都被锁定，从而提供更严格的并发控制。

## Mysql中的死锁排查？

**死锁的排查**

1.**查看错误日志**：MySQL的错误日志中可能会记录有关死锁的信息。通过查看这些日志，可以初步判断是否存在死锁以及死锁发生的时间和原因。

2.**使用SHOW ENGINE INNODB STATUS命令**：这个命令可以提供InnoDB存储引擎的详细信息，包括最近的死锁信息。在返回的结果中，可以查找"LATEST DETECTED DEADLOCK"部分，这里会详细描述死锁的情况，包括涉及的事务、锁定的资源等。

3.**性能监控工具**：使用如Percona Monitoring and Management (PMM)、InnoDB Plugin等工具可以帮助监控和分析数据库性能，并在发生死锁时提供警报。

4.**慢查询日志**：如果死锁是由于某些查询执行时间过长导致的，那么慢查询日志可能会记录这些查询。通过分析慢查询日志，可以找到可能导致死锁的长时间运行的查询。

**二、死锁的解决**

1.**调整事务隔离级别**：适当降低事务的隔离级别可以减少锁的竞争，但也可能带来其他问题，如不可重复读或幻读。需要根据具体业务需求权衡利弊。

2.**优化查询语句**：对涉及多表操作、复杂连接或子查询的语句进行优化，**以减少锁的持有时间和范围**。

3.**控制事务大小**：尽量将大事务拆分成多个小事务，以**减少锁的持有时间**。同时，避免在事务中执行不必要的操作。

4.**设置合理的锁超时时间**：通过设置合理的锁超时时间（如innodb_lock_wait_timeout参数），可以在一定程度上避免长时间的锁等待和死锁。

5.**开启主动死锁检测**:。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 `innodb_deadlock_detect` 设置为 on，表示开启这个逻辑，默认就开启。

6.**手动介入**：如果以上方法都无法解决死锁问题，或者需要立即解决已经发生的死锁，可以考虑手动终止其中一个事务来打破死锁状态。这通常需要谨慎操作，并确保不会影响到业务的正常运行。

## MYSQL日志

首先是**binlog**，也就是二进制日志。server层

作用：binlog记录了数据库所有的DDL（数据定义语言）和DML（数据操作语言）语句事件，这些语句会导致数据的改变。它主要用于数据复制和数据恢复。

格式：MySQL支持三种格式的binlog，分别是Statement-Based Replication(SBR)，记录SQL语句本身；Row-Based Replication(RBR)，记录行的改变；以及Mixed-Based Replication(MBR)，根据情况选择SBR或RBR。

工作原理：当一个事务被提交时，MySQL会将该事务的所有修改操作作为一个事件写入到binlog中。并且，MySQL会定期将内存中的binlog缓存刷新到磁盘上的binlog文件中。

接下来是**redo log**，也就是重做日志。

作用：redo log是InnoDB存储引擎特有的，用于保证事务的持久性和崩溃恢复。即使数据库崩溃，也可以通过redo log的回放来恢复已提交的事务。

结构：redo log是一个循环的、固定大小的日志文件，通常由多个物理文件组成。

写入过程：当事务执行修改操作时，MySQL首先将修改操作记录到内存中的redo log buffer缓冲区，然后定期将这些日志记录刷写到磁盘上的redo log文件中。

最后是**undo log**，即回滚日志。

作用：undo log主要用于事务的回滚和并发控制。当事务需要回滚时，可以使用undo log中保存的旧值将数据恢复到事务开始之前的状态。此外，undo log还用于多版本并发控制（MVCC），以提供事务的隔离性和并发访问的一致性。

工作原理：对于每个事务来说，其都有一个对应的undo log。当我们开启事务并对表进行操作后，这些操作都会被记录到undo log中。如果事务执行错误或需要回滚，就可以根据undo log中的信息将数据恢复到原来的状态。

## 什么是WAL？

**在redo log中，WAL （Write-Ahead Logging）技术**。**WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上**。

WAL的优点

- **实现事务的持久性，让 MySQL 有 crash-safe 的能力**，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失；
- WAL 技术的另外一个优点：**MySQL 的写操作从磁盘的「随机写」变成了「顺序写」**，提升语句的执行性能。这是因为 MySQL 的写操作并不是立刻更新到磁盘上，而是先记录在日志上，然后在合适的时间再更新到磁盘上

## MySQL的主从复制了解吗

MySQL 的主从复制依赖于 binlog ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复制的过程就是将 binlog 中的数据从主库传输到从库上。 这个过程一般是**异步**的，也就是主库上执行事务操作的线程不会等待复制 binlog 的线程同步完成。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/J0g14CUwaZeRYIdHD0Tdx6LbewL0NZRs9Ot8W8Ric2cFLmGz6XPOC5frbymEQicH5FLeGiaHvb8wFaPmWT5Hy2YdA/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

MySQL 集群的主从复制过程梳理成 3 个阶段：

- **写入 Binlog**：主库写 binlog 日志，提交事务，并更新本地存储数据。
- **同步 Binlog**：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。
- **回放 Binlog**：回放 binlog，并更新存储引擎中的数据。

具体详细过程如下：

- MySQL 主库在收到客户端提交事务的请求rt之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。
- 从库会创建一个专门的 I/O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。
- 从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。

在完成主从复制之后，你就可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。

## 主从复制的问题

数据丢失：主库宕机后，数据可能丢失，可以使用半同步复制

同步延迟：复制binlog（网络），重放（多线程）

### **主从延迟都有什么处理方法？**

**强制走主库方案**：对于大事务或资源密集型操作，直接在主库上执行，避免从库的额外延迟。

## buffer pool 中的数据什么时候刷盘？刷盘是怎样的流程？

下面几种情况会触发脏页的刷新：

- 当 redo log 日志满了的情况下，会主动触发脏页刷新到磁盘；
- Buffer Pool 空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘；
- MySQL 认为空闲时，后台线程会定期将适量的脏页刷入到磁盘；
- MySQL 正常关闭之前，会把所有的脏页刷入到磁盘；

刷盘的流程就是调用 write 将Buffer Pool 中的数据写入到操作系统的 pagecache，然后再调用 fsync 将 pagecache 中的数据写入到磁盘。

## 为什么需要两阶段提交？

事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致。

举个例子，假设 id = 1 这行数据的字段 name 的值原本是 'jay'，然后执行 `UPDATE t_user SET name = 'xiaolin' WHERE id = 1;` 如果在持久化 redo log 和 binlog 两个日志的过程中，出现了半成功状态，那么就有两种情况：

- **如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入**。MySQL 重启后，通过 redo log 能将 Buffer Pool 中 id = 1 这行数据的 name 字段恢复到新值 xiaolin，但是 binlog 里面没有记录这条更新语句，在主从架构中，binlog 会被复制到从库，由于 binlog 丢失了这条更新语句，从库的这一行 name 字段是旧值 jay，与主库的值不一致性；
- **如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入**。由于 redo log 还没写，崩溃恢复以后这个事务无效，所以 id = 1 这行数据的 name 字段还是旧值 jay，而 binlog 里面记录了这条更新语句，在主从架构中，binlog 会被复制到从库，从库执行了这条更新语句，那么这一行 name 字段是新值 xiaolin，与主库的值不一致性；

可以看到，在持久化 redo log 和 binlog 这两份日志的时候，如果出现半成功的状态，就会造成主从环境的数据不一致性。这是因为 redo log 影响主库的数据，binlog 影响从库的数据，所以 redo log 和 binlog 必须保持一致才能保证主从数据一致。

**MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决**，两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。

**两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是「准备（Prepare）阶段」和「提交（Commit）阶段」**，每个阶段都由协调者（Coordinator）和参与者（Participant）共同完成。注意，不要把提交（Commit）阶段和 commit 语句混淆了，commit 语句执行的时候，会包含提交（Commit）阶段。

举个拳击比赛的例子，两位拳击手（参与者）开始比赛之前，裁判（协调者）会在中间确认两位拳击手的状态，类似于问你准备好了吗？

- **准备阶段**：裁判（协调者）会依次询问两位拳击手（参与者）是否准备好了，然后拳击手听到后做出应答，如果觉得自己准备好了，就会跟裁判说准备好了；如果没有自己还没有准备好（比如拳套还没有带好），就会跟裁判说还没准备好。
- **提交阶段**：如果两位拳击手（参与者）都回答准备好了，裁判（协调者）宣布比赛正式开始，两位拳击手就可以直接开打；如果任何一位拳击手（参与者）回答没有准备好，裁判（协调者）会宣布比赛暂停，对应事务中的回滚操作。

### 两阶段提交的过程是怎样的？

在 MySQL 的 InnoDB 存储引擎中，开启 binlog 的情况下，MySQL 会同时维护 binlog 日志与 InnoDB 的 redo log，**为了保证这两个日志的一致性**，MySQL 使用了**内部 XA 事务**（是的，也有外部 XA 事务，跟本文不太相关，我就不介绍了），内部 XA 事务由 binlog 作为协调者，存储引擎是参与者。

当客户端执行 commit 语句或者在自动提交的情况下，MySQL 内部开启一个 XA 事务，**分两阶段来完成 XA 事务的提交**，如下图：

![image-20240525205713787](https://jiejiesks.oss-cn-beijing.aliyuncs.com/Note/202405252057203.png)

从图中可看出，事务的提交过程有两个阶段，就是**将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入binlog**，具体如下：

- **prepare 阶段**：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit = 1 的作用）；
- **commit 阶段**：把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog = 1 的作用），接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功；

### 异常重启会出现什么现象？

我们来看看在两阶段提交的不同时刻，MySQL 异常重启会出现什么现象？下图中有时刻 A 和时刻 B 都有可能发生崩溃：

![image-20240525205854165](https://jiejiesks.oss-cn-beijing.aliyuncs.com/Note/202405252058584.png)

不管是时刻 A（redo log 已经写入磁盘， binlog 还没写入磁盘），还是时刻 B （redo log 和 binlog 都已经写入磁盘，还没写入 commit 标识）崩溃，**此时的 redo log 都处于 prepare 状态**。

在 MySQL 重启后会按顺序扫描 redo log 文件，碰到处于 prepare 状态的 redo log，就拿着 redo log 中的 XID 去 binlog 查看是否存在此 XID：

- **如果 binlog 中没有当前内部 XA 事务的 XID，说明 redolog 完成刷盘，但是 binlog 还没有刷盘，则回滚事务**。对应时刻 A 崩溃恢复的情况。
- **如果 binlog 中有当前内部 XA 事务的 XID，说明 redolog 和 binlog 都已经完成了刷盘，则提交事务**。对应时刻 B 崩溃恢复的情况。

可以看到，**对于处于 prepare 阶段的 redo log，即可以提交事务，也可以回滚事务，这取决于是否能在 binlog 中查找到与 redo log 相同的 XID**，如果有就提交事务，如果没有就回滚事务。这样就可以保证 redo log 和 binlog 这两份日志的一致性了。

所以说，**两阶段提交是以 binlog 写成功为事务提交成功的标识**，因为 binlog 写成功了，就意味着能在 binlog 中查找到与 redo log 相同的 XID。

## SQL注入？如何防止？

SQL注入的基本原理是利用应用程序未对用户输入进行充分验证的漏洞，直接将用户输入嵌入到SQL查询中，从而改变SQL语句的逻辑。

**使用参数化查询（Prepared Statements）**: 参数化查询将SQL语句和输入数据分离，输入数据作为参数传递，避免了直接拼接SQL语句。例如，使用Python的`sqlite3`库时：

```
cursor.execute("SELECT * FROM users WHERE username = ? AND password = ?", (username, password))
```

**输入验证与过滤**: 在服务器端验证和过滤用户输入，确保输入的数据类型、长度、格式等符合预期。例如，拒绝包含SQL关键字的输入，或对输入进行转义处理。
