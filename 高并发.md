## 高并发背景

互联网行业迅速发展，用户量剧增，系统面临巨大的并发请求压力。

软件系统有三个追求：**高性能、高并发、高可用**，俗称三高。三者既有区别也有联系，门门道道很多，全面讨论需要三天三夜，本篇讨论高并发

## 高并发对系统的挑战

性能下降、资源竞争和稳定性问题等

# 什么是高并发

## 高并发的定义

高并发是指系统或应用程序在同一时间段内接收到大量并发请求的能力。具体来说，高并发环境下系统需要能够同时处理大量的请求，而不会出现性能问题或响应延迟

## 高并发的特点

1. 大量请求：高并发场景下，系统需要同时处理大量的请求，这些请求可能来自于不同的用户或客户端。
2. 同时访问：这些请求几乎同时到达系统，需要在短时间内进行处理和响应。
3. 资源竞争：由于大量请求同时到达，系统的资源（如CPU、内存、网络带宽等）可能会面临竞争和争夺。
4. 响应时间要求高：高并发场景通常对系统的响应速度有较高的要求，用户期望能够快速获取响应结果

## 高并发场景和应用

高并发场景广泛应用于热门网站、电商平台、社交媒体等互联网应用中。例如，在电商平台上有大量用户同时浏览、搜索商品，提交订单等操作；社交媒体平台上有大量用户同时发布、点赞、评论等操作。这些场景需要系统能够同时处理大量请求，并保证系统的性能、可用性和用户体验

## 高并发的影响

- 系统性能的下降和延迟增加
- 资源竞争和资源耗尽
- 系统稳定性和可用性的挑战

# 高并发应对策略

- 缓存：缓解系统负载压力，提高系统响应速度
- 限流：控制并发访问量，保护系统免受过载影响
- 降级：保证核心功能的稳定性，舍弃非关键业务或简化处理

# 缓存

## 简介

在网站或APP的开发中，缓存机制是一个不可或缺的环节，可以提高网站或APP的访问速度，降低数据库压力。但在高并发环境下，缓存机制的作用更加明显，不仅可以有效减轻数据库的负载，还可以提高系统的稳定性和性能，从而给用户带来更好的体验

## 工作原理

缓存的工作原理是先从缓存中获取数据，如果有数据则直接返回给用户，如果没有数据则从慢速设备上读取实际数据并且将数据放入缓存。

## 常用技术

### 浏览器缓存

#### 简介

浏览器缓存是指将网页中的资源（如HTML、CSS、JavaScript、图像等）存储在用户的浏览器内部，以便在后续请求同一资源时可以直接从本地缓存中获取，而无需再次从服务器下载

#### 适用场景

浏览器缓存适用于那些静态内容变化较少的网页和静态资源，可以显著提升网站性能和用户体验，并减少服务器的负载

#### 常见用法

使用浏览器缓存可以通过设置响应头中的Expires和Cache-Control字段来控制缓存的行为。

1. 使用Expires字段：Expires字段指定了缓存的过期时间，是一个具体的日期和时间。服务器可以在响应头中添加Expires字段，告诉浏览器在该时间之前可以直接从缓存中获取资源，而无需再向服务器发起请求。例如：Expires: Mon, 31 Dec 2022 23:59:59 GMT。
2. 使用Cache-Control字段：Cache-Control字段提供了更灵活的缓存控制选项。可以通过设置max-age指令来指定缓存的最大有效时间，单位是秒。例如：Cache-Control: max-age=3600 表示资源可以在1小时内直接从缓存中获取。还可以使用其他指令，如no-cache表示缓存但不使用缓存、no-store表示禁止缓存等。

#### 注意事项

浏览器缓存存储实时性不敏感的数据，如商品框架、商家评分、评价和广告词。它有过期时间，并通过响应头进行控制。实时性要求高的数据不适合使用浏览器缓存

### 客户端缓存

#### 简介

客户端缓存是将数据存储在浏览器中，以提高访问速度和减少服务器请求

#### 适用场景

在大促期间，为了防止服务端承受瞬间的高流量压力，可以提前将一些素材（如js/css/image等）下发到客户端进行缓存，避免在大促期间再次请求这些素材。此外，还可以将一些兜底数据或样式文件存放在客户端缓存中，以确保在服务端异常或网络异常的情况下，保持app的正常运行。

### CDN缓存

#### 简介

CDN（Content Delivery Network）是建立在承载网之上的分布式网络，由分布在不同区域的边缘节点服务器组成。

CDN缓存通常用于存放静态页面数据、活动页面、图片等数据。它有两种缓存机制：推送机制（将数据主动推送到CDN节点）和拉取机制（首次访问时从源服务器获取数据并存储在CDN节点）。

#### 适用场景

CDN缓存可以提高网站访问速度，适用于网站访问量大、访问速度慢、数据变化不频繁的场景

#### 常用工具以及用法

常见的CDN缓存工具包括Cloudflare、Akamai、Fastly和AWS CloudFront等。这些工具提供了全球分布的CDN网络，以加速内容传输和提升性能。它们提供了控制台和API，用于配置CDN缓存规则、管理缓存内容、刷新和更新缓存等

### 反向代理缓存

#### 简介

反向代理缓存是指在反向代理服务器上对请求的响应进行缓存，以提高服务的性能和用户体验。它将经常请求的静态内容缓存在代理服务器上，当有用户请求同样的内容时，代理服务器会直接返回缓存的响应，而无需再次向源服务器请求

#### 适用场景

适用于访问外部服务速度比较慢，但是**数据变化不频繁**的场景。

#### 常用工具以及用法

1. **Nginx**：一款高性能的反向代理服务器，支持反向代理缓存功能，可通过配置文件进行缓存策略的设置。Nginx代理层缓存主要以Http模块与proxy_cacahe模块进行配置即可。
2. **Varnish**：一个专门用于反向代理缓存的开源软件，可以高效地缓存并提供快速的响应。
3. **Squid**：一款功能强大的缓存代理服务器，支持反向代理缓存和正向代理缓存。

### 本地缓存

#### 简介

本地缓存是将数据或资源存储在客户端的存储介质中，如硬盘、内存或数据库。它可以是临时的，只在应用程序运行期间有效，或者可以是持久的，即在不同的应用程序会话中保持有效

#### 适用场景

本地缓存适用于频繁访问数据、离线访问、减少带宽消耗和提升用户体验的场景。

#### 常用工具以及用法

**一般分为磁盘缓存**、**CPU缓存**、**应用缓存**

1. 磁盘缓存：存储在硬盘等永久性存储介质上，用于加速数据的读取和访问。
2. CPU缓存：位于处理器内部的高速存储器，用于暂时存储频繁访问的数据或指令，提高计算机的性能。
3. 应用缓存：存储在内存中的应用程序数据或资源，用于提高应用程序的响应速度和用户体验。用Java服务来举例，又分为 堆内缓存 与 堆外缓存 。

### 分布式缓存

#### 简介

分布式缓存是将缓存数据分散存储在多台服务器上的缓存解决方案

#### 适用场景

高并发读取、数据共享和协同处理、提供弹性和可扩展性、降低后端请求次数等场景

#### 常用工具以及用法

1. Redis：Redis是一种高性能的键值存储系统，支持丰富的数据类型和灵活的缓存策略。可以使用Redis搭建分布式缓存集群，利用其快速的读写能力和一致性哈希算法实现数据分片和负载均衡。
2. Memcached：Memcached是一种简单而快速的分布式内存对象缓存系统，用于减轻数据库负载和加速动态Web应用程序。它采用分布哈希算法进行数据分片和分布式存储。
3. Hazelcast：Hazelcast是一个开源的分布式内存数据网格平台，提供分布式缓存和分布式计算能力。它可以用于构建高吞吐量和高可用性的分布式缓存系统。

## 缓存问题

### 缓存穿透

缓存穿透是指数据库和缓存都没有的数据，每次都要经过缓存去访问数据库，大量的请求有可能导致DB宕机。（强调都没有数据+并发访问）

**解决方案：**

接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；

从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为**key-null**，**缓存有效时间可以设置短点**，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击

### 缓存击穿

缓存击穿是指数据库有，缓存没有的数据，大量请求访问**这个**缓存不存在的数据，最后请求打到DB可能导致DB宕机。（强调单个Key过期+并发访问）

**解决方案：**

​	1.设置热点数据永远不过期。

​	2.接口限流与熔断，降级。重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些 服务 不可用时候，进行熔断，失败快速返回机制。

​	3.布隆过滤器。bloomfilter就类似于一个hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于hash算法和容器大小，

### 缓存雪崩

缓存雪崩是指数据库有，缓存没有的数据，大量请求访问**这些**缓存不存在的数据，最后请求打到DB可能导致DB宕机。（强调批量Key过期+并发访问）

**解决方案**：

1. 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
2. 如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。
3. 设置热点数据永远不过期。

### 缓存一致性

缓存一致性指的是缓存与DB之间的数据一致性，我们需要通过各种手段来防止缓存与DB不一致，我们要保证缓存与DB的数据一致或者数据最终一致。

### 其他

缓存的好处我们非常受益，用户的每一次请求都伴随着无数缓存的诞生，但是缓存同时也给我们带来了不小的挑战，比如在上面提到的一些疑难课题：缓存穿透、缓存击穿、缓存雪崩和缓存一致性。

除此之外，我们还会涉及到其他的一些缓存难题，如：缓存倾斜、缓存阻塞、缓存慢查询、缓存主从一致性问题、缓存高可用、缓存故障发现与故障恢复、集群扩容收缩、大Key热Key......

# 限流

## 简介

再强大的系统，也怕流量短事件内集中爆发，就像银行怕挤兑一样，所以，高并发另一个必不可少的模块就是限流。

限流是一种通过控制请求的速率或数量来保护系统免受过载的技术。流控的精髓是限制单位时间内的请求量，最大程度保障系统的可靠性及可用性

## 作用

限流是在高并发环境下，为了保护系统的稳定性和可用性而引入的一种策略。通过限制并发请求的数量或频率，可以防止系统被过多的请求压垮或耗尽资源

## 服务端限流（限流算法）

常见的流控算法包括：固定窗口、滑动窗口、漏桶、令牌桶、滑动日志等算法

手搓:

https://www.cnblogs.com/liqiangchn/p/14253924.html

#### 固定窗口算法（计数器）

##### 简介

固定窗口限流算法（Fixed Window Rate Limiting Algorithm）是一种最简单的限流算法，其原理是在固定时间窗口(单位时间)内限制请求的数量

![image-20250106194943221](C:\Users\liwei\AppData\Roaming\Typora\typora-user-images\image-20250106194943221.png)

##### 原理

固定窗口是最简单的流控算法。即，给定时间窗口，维护一个计数器用于统计访问次数，并实现以下规则：

1. 如果访问次数小于阈值，则允许访问，访问次数+1；
2. 如果访问次数超出阈值，则限制访问，访问次数不增；
3. 如果超过了时间窗口，计数器清零，并重置清零后的首次成功访问时间为当前时间。

##### 适用场景

- 保护后端服务免受大流量冲击，避免服务崩溃。
- 对 API 调用进行限制，保证公平使用。
- 防止恶意用户对服务进行洪水攻击

##### 优劣分析

- 优点
- 固定窗口算法非常简单，易于实现和理解。性能高
- 缺点
- 存在明显的临界问题 	eg: 	比如: 假设限流阀值为5个请求，单位时间窗口是1s，如果我们在单位时间内的前0.8-1s和1-1.2s，分别并发5个请求。虽然都没有超过阀值，但是如果算0.8-1.2s内的，则并发数高达10，已经超过单位时间1s不超过5阀值的定义了。

#### 滑动窗口算法

##### 简介

为了解决临界突变问题，可以引入滑动窗口。即：把大的时间窗口拆分成若干粒度更细的子窗口，每个子窗口独立统计，按子窗口时间滑动，统一限流。

当滑动窗口的格子周期划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。

![image-20250106194925415](C:\Users\liwei\AppData\Roaming\Typora\typora-user-images\image-20250106194925415.png)

##### 原理

将单位时间周期分为n个小周期，分别记录每个小周期内接口的访问次数，并且根据时间滑动删除过期的小周期。它可以解决固定窗口临界值的问题

假设单位时间还是1s，滑动窗口算法把它划分为5个小周期，也就是滑动窗口（单位时间）被划分为5个小格子。每格表示0.2s。每过0.2s，时间窗口就会往右滑动一格。然后呢，每个小周期，都有自己独立的计数器，如果请求是0.83s到达的，0.8~1.0s对应的计数器就会加1。

假设我们1s内的限流阀值还是5个请求，0.8~1.0s内（比如0.9s的时候）来了5个请求，落在黄色格子里。

时间过了1.0s这个点之后，又来5个请求，落在紫色格子里。如果是固定窗口算法，是不会被限流的，但是滑动窗口的话，每过一个小周期，它会右移一个小格。过了1.0s这个点后，会右移一小格，当前的单位时间段是0.2~1.2s，这个区域的请求已经超过限定的5了，已触发限流啦，实际上，紫色格子的请求都被拒绝

##### 适用场景

同固定窗口的场景，且对流量限制要求较高的场景，`需要更好地应对突发流量`。

##### 优劣分析

- 优势
- 简单易懂精度高（通过调整时间窗口的大小来实现不同的限流效果）可扩展性强（可以非常容易地与其他限流算法结合使用）
- 劣质 突发流量无法处理（无法应对短时间内的大量请求，但是一旦到达限流后，请求都会直接暴力被拒绝。这样我们会损失一部分请求，这其实对于产品来说，并不太友好），需要合理调整时间窗口大小

#### 漏桶算法

##### 简介

**基于（出口）流速来做流控**。在网络通信中常用于流量整形，可以很好地解决平滑度问题

##### 特点

- 可以以任意速率流入水滴到漏桶（流入请求）
- 漏桶具有固定容量，出水速率是固定常量（流出请求）
- 如果流入水滴超出了桶的容量，则流入的水滴溢出（新请求被拒绝）

##### 原理

- 思想

将数据包看作是水滴，漏桶看作是一个固定容量的水桶，数据包像水滴一样从桶的顶部流入桶中，并通过桶底的一个小孔以一定的速度流出，从而限制了数据包的流量

- 工作原理

对于每个到来的数据包，都将其加入到漏桶中，并检查漏桶中当前的水量是否超过了漏桶的容量。



如果超过了容量，就将多余的数据包丢弃。如果漏桶中还有水，就以一定的速率从桶底输出数据包，保证输出的速率不超过预设的速率，从而达到限流的目的。

##### 适用场景

一般用于保护第三方的系统，比如自身的系统需要调用第三方的接口，为了保护第三方的系统不被自身的调用打垮，便可以通过漏斗算法进行限流，保证自身的流量平稳的打到第三方的接口上

##### 优劣分析

- 优势
- 可以平滑限制请求的处理速度，避免瞬间请求过多导致系统崩溃或者雪崩。可以控制请求的处理速度，使得系统可以适应不同的流量需求，避免过载或者过度闲置。可以通过调整桶的大小和漏出速率来满足不同的限流需求，可以灵活地适应不同的场景。
- 劣质
- 需要对请求进行缓存，会增加服务器的内存消耗。对于流量波动比较大的场景，需要较为灵活的参数配置才能达到较好的效果。但是面对突发流量的时候，漏桶算法还是循规蹈矩地处理请求，这不是我们想看到的啦。流量变突发时，我们肯定希望系统尽量快点处理请求，提升用户体验嘛。

#### 令牌桶算法

##### 简介

基于（入口）流速来做流控的一种限流算法

##### 原理

该算法维护一个固定容量的令牌桶，每秒钟会向令牌桶中放入一定数量的令牌。当有请求到来时，如果令牌桶中有足够的令牌，则请求被允许通过并从令牌桶中消耗一个令牌，否则请求被拒绝。

Guava的RateLimiter限流组件，就是基于令牌桶算法实现的。

##### 适用场景

一般用于保护自身的系统，对调用者进行限流，保护自身的系统不被突发的流量打垮。如果自身的系统实际的处理能力强于配置的流量限制时，可以允许一定程度的流量突发，使得实际的处理速率高于配置的速率，充分利用系统资源

##### 优劣分析

- 优势
- 稳定性高：令牌桶算法可以控制请求的处理速度，可以使系统的负载变得稳定。精度高：令牌桶算法可以根据实际情况动态调整生成令牌的速率，可以实现较高精度的限流。弹性好：令牌桶算法可以处理突发流量，可以在短时间内提供更多的处理能力，以处理突发流量。
- 劣质
- 实现复杂：相对于固定窗口算法等其他限流算法，令牌桶算法的实现较为复杂。对短时请求难以处理：在短时间内有大量请求到来时，可能会导致令牌桶中的令牌被快速消耗完，从而限流。这种情况下，可以考虑使用漏桶算法。时间精度要求高：令牌桶算法需要在固定的时间间隔内生成令牌，因此要求时间精度较高，如果系统时间不准确，可能会导致限流效果不理想。

#### 滑动日志算法（比较冷门）

##### 简介

滑动日志限速算法需要记录请求的时间戳，通常使用有序集合来存储，我们可以在单个有序集合中跟踪用户在一个时间段内所有的请求。

##### 优劣分析

- 优势 滑动日志能够避免突发流量，实现较为精准的限流更加灵活，能够支持更加复杂的限流策略 	如多级限流，每分钟不超过100次，每小时不超过300次，每天不超过1000次，我们只需要保存最近24小时所有的请求日志即可实现。
- 劣质**占用存储空间要高于其他限流算法**

#### 几种算法小结

固定窗口算法实现简单，性能高，但是会有临界突发流量问题，瞬时流量最大可以达到阈值的2倍。

为了解决临界突发流量，可以将窗口划分为多个更细粒度的单元，每次窗口向右移动一个单元，于是便有了滑动窗口算法。

滑动窗口当流量到达阈值时会瞬间掐断流量，所以导致流量不够平滑。

想要达到限流的目的，又不会掐断流量，使得流量更加平滑？可以考虑漏桶算法！需要注意的是，漏桶算法通常配置一个FIFO的队列使用以达到允许限流的作用。

由于速率固定，即使在某个时刻下游处理能力过剩，也不能得到很好的利用，这是漏桶算法的一个短板。

限流和瞬时流量其实并不矛盾，在大多数场景中，短时间突发流量系统是完全可以接受的。令牌桶算法就是不二之选了，令牌桶以固定的速率v产生令牌放入一个固定容量为n的桶中，当请求到达时尝试从桶中获取令牌。

当桶满时，允许最大瞬时流量为n；当桶中没有剩余流量时则限流速率最低，为令牌生成的速率v。

如何实现更加灵活的多级限流呢？滑动日志限流算法了解一下！这里的日志则是请求的时间戳，通过计算制定时间段内请求总数来实现灵活的限流。

当然，由于需要存储时间戳信息，其占用的存储空间要比其他限流算法要大得多。

以上几种限流算法的实现都仅适合单机限流。虽然给每台机器平均分配限流配额可以达到限流的目的，但是由于机器性能，流量分布不均以及计算数量动态变化等问题，单机限流在分布式场景中的效果总是差强人意。

分布式限流最简单的实现就是利用中心化存储，即将单机限流存储在本地的数据存储到同一个存储空间中，如常见的Redis等。

## 容器限流

### Tomcat 限流

Tomcat 8.5 版本的最大线程数在 conf/server.xml 配置中，如下所示：

```xml
<Connector port="8080" protocol="HTTP/1.1"
          connectionTimeout="20000"
          maxThreads="150"
          redirectPort="8443" />
```

其中 `maxThreads` 就是 Tomcat 的最大线程数，当请求的并发大于此值（maxThreads）时，请求就会排队执行，这样就完成了限流的目的。

> 小贴士：maxThreads 的值可以适当的调大一些，此值默认为 150（Tomcat 版本 8.5.42），但这个值也不是越大越好，要看具体的硬件配置，需要注意的是每开启一个线程需要耗用 1MB 的 JVM 内存空间用于作为线程栈之用，并且线程越多 GC 的负担也越重。最后需要注意一下，操作系统对于进程中的线程数有一定的限制，Windows 每个进程中的线程数不允许超过 2000，Linux 每个进程中的线程数不允许超过 1000。

### Nginx

#### 简介

Nginx从网关这一层面考虑，可以作为最前置的网关，抵挡大部分的网络流量，因此使用Nginx进行限流也是一个很好的选择，在Nginx中，也提供了常用的基于限流相关的策略配置.

#### 用法

Nginx 提供了两种限流方法：一种是控制速率，另一种是控制并发连接数。

##### 控制速率

我们需要使用 `limit_req_zone `用来限制单位时间内的请求数，即速率限制，

因为Nginx的限流统计是基于毫秒的，我们设置的速度是 `2r/s`，转换一下就是500毫秒内单个IP只允许通过1个请求，从501ms开始才允许通过第2个请求。

- **控制速率优化版**

上面的速率控制虽然很精准但是在生产环境未免太苛刻了，实际情况下我们应该控制一个IP单位总时间内的总访问次数，而不是像上面那样精确到毫秒，我们可以使用 burst 关键字开启此设置

`burst=4`意思是每个IP最多允许4个突发请求

##### 控制并发数

利用`limit_conn_zone` 和 `limit_conn` 两个指令即可控制并发数

其中 `limit_conn perip` 10 表示限制单个 IP 同时最多能持有 10 个连接；`limit_conn perserver `100 表示 server 同时能处理并发连接的总数为 100 个。

注意：只有当 request header 被后端处理后，这个连接才进行计数。

## 合法性验证限流

比如验证码、IP 黑名单等，这些手段可以有效的防止恶意攻击和爬虫采集。

# 降级

## 简介

降级是在高并发或异常情况下舍弃非关键业务或简化处理的一种技术手段

按类型可分为有感降级，无感降级

### 有感降级

主要是通过一定的监控感知到异常出现或即将出现，对调用服务进行快速失败返回或者进行切换，在指标回正的时候恢复服务调用，这个也可以称为熔断。

### 无感降级

系统不作感知，在调用服务出现异常则自动忽略，进行空返回或无操作。降级的本质为作为服务调用方去规避提供方带来的风险。

## 原理

在限流中，服务调用方为每一个调用的服务维护一个有限状态机，在这个状态机会有三种状态：关闭（调用远程服务）、半打开（尝试调用远程服务）和打开（返回错误）。这三种状态之间切换的过程如下：

当调用失败的次数累积到一定的阈值时，熔断机制从关闭态切换到打开态。一般在实现时，如果调用成功一次，就会重置调用失败次数

当熔断处于打开状态时，我们会启动一个计时器，当计时器超时后，状态切换到半打开态。也可以通过设置一个定时器，定期的探测服务是否恢复

当熔断处于半打开状态时，请求可以达到后端服务，如果累计一定的成功次数后，状态切换到关闭态；如果出现调用失败的情况，则切换到打开态

## 常用工具

1. 降级开源组件：**sentinel**和**Hystrix(不展开)**
2. 手动降级：可采用系统配置开关来控制

## 其他

### 熔断

#### 简介

熔断在程序中，表示“断开”的意思。如发生了某事件，程序为了整体的稳定性，所以暂时（断开）停止服务一段时间，以保证程序可用时再被使用。

#### 熔断和降级的区别

- **概念不同** 熔断程序为了整体的稳定性，所以暂时（断开）停止服务一段时间；降级（Degradation）降低级别的意思，它是指程序在出现问题时，仍能保证有限功能可用的一种机制
- **触发条件不同** 不同框架的熔断和降级的触发条件是不同，以Hystrix为例： Hystrix 熔断触发条件

默认情况 hystrix 如果检测到 10 秒内请求的失败率超过 50%，就触发熔断机制。之后每隔 5 秒重新尝试请求微服务，如果微服务不能响应，继续走熔断机制。如果微服务可达，则关闭熔断机制，恢复正常请求。

​    \* Hystrix 降级触发条件

默认情况下，hystrix 在以下 4 种条件下都会触发降级机制：

1. 方法抛出 HystrixBadRequestException
2. 方法调用超时
3. 熔断器开启拦截调用
4. 线程池或队列或信号量已满

- **归属关系不同熔断时可能会调用降级机制，而降级时通常不会调用熔断机制。**因为熔断是从全局出发，为了保证系统稳定性而停用服务，而降级是退而求其次，提供一种保底的解决方案，所以它们的归属关系是不同（熔断 > 降级）

# 小结

- 缓存、限流和降级是应对高并发的三大利器，能够提升系统性能、保护资源和保证核心功能。
- 组合使用缓存、限流和降级策略，根据具体场景灵活调整和优化。
- 在高并发环境下，综合使用三大利器是应对挑战的有效策略。

